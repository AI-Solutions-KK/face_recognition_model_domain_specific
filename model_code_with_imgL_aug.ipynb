{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T05:18:34.126244Z",
     "start_time": "2025-11-15T05:12:04.597975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: facenet-pytorch in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from facenet-pytorch) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (80.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests->facenet-pytorch) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests->facenet-pytorch) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests->facenet-pytorch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests->facenet-pytorch) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Run once in a notebook cell to install all required packages used in the notebook\n",
    "# (includes augmentation code, facenet-pytorch, and the Keras/TensorFlow bits)\n",
    "\n",
    "# !pip install numpy pandas matplotlib pillow opencv-python facenet-pytorch scikit-learn tqdm torch torchvision tensorflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c129e2b0728ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use below cmd in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64e879f24240da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal command (Remove # and run below cmd in terminal )\n",
    "\n",
    "# pip install ipykernel notebook jupyterlab numpy pandas matplotlib pillow opencv-python facenet-pytorch scikit-learn tqdm torch torchvision tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0277bb17dbdb8e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:03:01.868866Z",
     "start_time": "2025-11-15T17:02:44.344853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting augmentation (sequential Aug filenames, dynamic TARGET = max class size).\n",
      "Using dataset root: human_face_dataset\\pins_face_recognition\n",
      "Computed dynamic TARGET (max class size) = 237\n",
      "\n",
      "Found 105 class folders. Augmenting classes with < 237 images to reach 237 per class...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:10<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ augmentation_report.csv saved.\n",
      "                      class  original  synthetic  total\n",
      "          pins_Adriana Lima       237          0    237\n",
      "          pins_Alex Lawther       237          0    237\n",
      "    pins_Alexandra Daddario       237          0    237\n",
      "          pins_Alvaro Morte       237          0    237\n",
      "           pins_Amanda Crew       237          0    237\n",
      "          pins_Andy Samberg       237          0    237\n",
      "         pins_Anne Hathaway       237          0    237\n",
      "        pins_Anthony Mackie       237          0    237\n",
      "         pins_Avril Lavigne       237          0    237\n",
      "           pins_Ben Affleck       237          0    237\n",
      "            pins_Bill Gates       237          0    237\n",
      "          pins_Bobby Morley       237          0    237\n",
      "      pins_Brenton Thwaites       237          0    237\n",
      "        pins_Brian J. Smith       237          0    237\n",
      "           pins_Brie Larson       237          0    237\n",
      "           pins_Chris Evans       237          0    237\n",
      "       pins_Chris Hemsworth       237          0    237\n",
      "           pins_Chris Pratt       237          0    237\n",
      "        pins_Christian Bale       237          0    237\n",
      "     pins_Cristiano Ronaldo       237          0    237\n",
      "    pins_Danielle Panabaker       237          0    237\n",
      "       pins_Dominic Purcell       237          0    237\n",
      "        pins_Dwayne Johnson       237          0    237\n",
      "          pins_Eliza Taylor       237          0    237\n",
      "        pins_Elizabeth Lail       237          0    237\n",
      "         pins_Emilia Clarke       237          0    237\n",
      "            pins_Emma Stone       237          0    237\n",
      "           pins_Emma Watson       237          0    237\n",
      "       pins_Gwyneth Paltrow       237          0    237\n",
      "           pins_Henry Cavil       237          0    237\n",
      "          pins_Hugh Jackman       237          0    237\n",
      "            pins_Inbar Lavi       237          0    237\n",
      "           pins_Irina Shayk       237          0    237\n",
      "         pins_Jake Mcdorman       237          0    237\n",
      "           pins_Jason Momoa       237          0    237\n",
      "     pins_Jennifer Lawrence       237          0    237\n",
      "         pins_Jeremy Renner       237          0    237\n",
      "        pins_Jessica Barden       237          0    237\n",
      "          pins_Jimmy Fallon       237          0    237\n",
      "           pins_Johnny Depp       237          0    237\n",
      "           pins_Josh Radnor       237          0    237\n",
      "      pins_Katharine Mcphee       237          0    237\n",
      "    pins_Katherine Langford       237          0    237\n",
      "          pins_Keanu Reeves       237          0    237\n",
      "        pins_Krysten Ritter       237          0    237\n",
      "     pins_Leonardo DiCaprio       237          0    237\n",
      "         pins_Lili Reinhart       237          0    237\n",
      "        pins_Lindsey Morgan       237          0    237\n",
      "          pins_Lionel Messi       237          0    237\n",
      "          pins_Logan Lerman       237          0    237\n",
      "      pins_Madelaine Petsch       237          0    237\n",
      "       pins_Maisie Williams       237          0    237\n",
      "         pins_Maria Pedraza       237          0    237\n",
      "    pins_Marie Avgeropoulos       237          0    237\n",
      "          pins_Mark Ruffalo       237          0    237\n",
      "       pins_Mark Zuckerberg       237          0    237\n",
      "             pins_Megan Fox       237          0    237\n",
      "           pins_Miley Cyrus       237          0    237\n",
      "    pins_Millie Bobby Brown       237          0    237\n",
      "       pins_Morena Baccarin       237          0    237\n",
      "        pins_Morgan Freeman       237          0    237\n",
      "          pins_Nadia Hilker       237          0    237\n",
      "        pins_Natalie Dormer       237          0    237\n",
      "       pins_Natalie Portman       237          0    237\n",
      "   pins_Neil Patrick Harris       237          0    237\n",
      "          pins_Pedro Alonso       237          0    237\n",
      "          pins_Penn Badgley       237          0    237\n",
      "            pins_Rami Malek       237          0    237\n",
      "      pins_Rebecca Ferguson       237          0    237\n",
      "        pins_Richard Harmon       237          0    237\n",
      "               pins_Rihanna       237          0    237\n",
      "        pins_Robert De Niro       237          0    237\n",
      "      pins_Robert Downey Jr       237          0    237\n",
      "   pins_Sarah Wayne Callies       237          0    237\n",
      "          pins_Selena Gomez       237          0    237\n",
      "pins_Shakira Isabel Mebarak       237          0    237\n",
      "         pins_Sophie Turner       237          0    237\n",
      "         pins_Stephen Amell       237          0    237\n",
      "          pins_Taylor Swift       237          0    237\n",
      "            pins_Tom Cruise       237          0    237\n",
      "             pins_Tom Hardy       237          0    237\n",
      "        pins_Tom Hiddleston       237          0    237\n",
      "           pins_Tom Holland       237          0    237\n",
      "    pins_Tuppence Middleton       237          0    237\n",
      "        pins_Ursula Corbero       237          0    237\n",
      "      pins_Wentworth Miller       237          0    237\n",
      "             pins_Zac Efron       237          0    237\n",
      "               pins_Zendaya       237          0    237\n",
      "           pins_Zoe Saldana       237          0    237\n",
      "   pins_alycia dabnem carey       237          0    237\n",
      "           pins_amber heard       237          0    237\n",
      "          pins_barack obama       237          0    237\n",
      "        pins_barbara palvin       237          0    237\n",
      "         pins_camila mendes       237          0    237\n",
      "       pins_elizabeth olsen       237          0    237\n",
      "            pins_ellen page       237          0    237\n",
      "             pins_elon musk       237          0    237\n",
      "             pins_gal gadot       237          0    237\n",
      "          pins_grant gustin       237          0    237\n",
      "            pins_jeff bezos       237          0    237\n",
      "        pins_kiernen shipka       237          0    237\n",
      "         pins_margot robbie       237          0    237\n",
      "        pins_melissa fumero       237          0    237\n",
      "    pins_scarlett johansson       237          0    237\n",
      "             pins_tom ellis       237          0    237\n",
      "\n",
      "‚úÖ Updated paths list saved to: embeddings_cache\\paths_augmented.npy  (len=24885)\n",
      "\n",
      "================================================================================\n",
      "üìä NEW BALANCE STATUS (images on disk)\n",
      "================================================================================\n",
      "Min per class: 237\n",
      "Max per class: 237\n",
      "Target: 237\n",
      "‚úÖ All classes reached TARGET.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# PREPROCESSING\n",
    "\n",
    "# Block A: Augmentation Block\n",
    "\n",
    "# [Real-image augmentation (Image-Level; BALANCE -> dynamic MAX)]\n",
    "\n",
    "# - Keeps the same structure / helpers as your original cell\n",
    "# - Computes TARGET = current maximum class size (dynamic) and brings every class\n",
    "#   up to that exact count (no class will exceed TARGET after run)\n",
    "# - Saves synthetic images into same class folders with marker '_Aug_'\n",
    "# - Produces augmentation_report.csv with columns: class, original, synthetic, total\n",
    "# - Updates embeddings_cache/paths_augmented.npy (so Block 7 can pick up new file list)\n",
    "# NOTE: This is a drop-in replacement of your previous Block 6B. Core augmentation\n",
    "#       internals are preserved; only target computation & flow adjusted.\n",
    "################################################################################\n",
    "print(\"Starting augmentation (sequential Aug filenames, dynamic TARGET = max class size).\")\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageEnhance\n",
    "import random, shutil, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Config ----------\n",
    "SYN_MARK = \"_Aug_\"                  # new naming marker\n",
    "SRC_CANDIDATES = [\n",
    "    Path('human_face_dataset') / 'pins_face_recognition',\n",
    "    Path('human_face_dataset'),\n",
    "]\n",
    "IMG_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n",
    "CACHE_DIR = Path('embeddings_cache')\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "paths_augmented_file = CACHE_DIR / 'paths_augmented.npy'\n",
    "augmentation_report_csv = Path('augmentation_report.csv')\n",
    "\n",
    "# ---------- locate dataset ----------\n",
    "dataset_root = None\n",
    "for cand in SRC_CANDIDATES:\n",
    "    if cand.exists() and cand.is_dir():\n",
    "        subdirs = [p for p in cand.iterdir() if p.is_dir()]\n",
    "        if len(subdirs) > 0:\n",
    "            dataset_root = cand\n",
    "            break\n",
    "\n",
    "if dataset_root is None:\n",
    "    raise FileNotFoundError(\"Dataset root not found. Checked: \" + \", \".join(map(str, SRC_CANDIDATES)))\n",
    "\n",
    "print(f\"Using dataset root: {dataset_root}\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "_int_re = re.compile(r'(\\d+)')\n",
    "def max_number_in_filename(fname):\n",
    "    nums = [int(m.group(1)) for m in _int_re.finditer(fname)]\n",
    "    return max(nums) if nums else 0\n",
    "\n",
    "def display_name_from_folder(folder_name):\n",
    "    if folder_name.startswith('pins_'):\n",
    "        return folder_name[len('pins_'):]\n",
    "    return folder_name\n",
    "\n",
    "def list_image_files(folder):\n",
    "    return sorted([p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in IMG_EXTS])\n",
    "\n",
    "def augment_image_save(src_path: Path, dst_path: Path):\n",
    "    try:\n",
    "        im = Image.open(src_path).convert('RGB')\n",
    "    except Exception:\n",
    "        return False\n",
    "    if random.random() < 0.5:\n",
    "        im = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    if random.random() < 0.4:\n",
    "        im = im.rotate(random.choice([0,90,180,270]), expand=False)\n",
    "    if random.random() < 0.6:\n",
    "        im = ImageEnhance.Color(im).enhance(random.uniform(0.85,1.15))\n",
    "    if random.random() < 0.5:\n",
    "        im = ImageEnhance.Brightness(im).enhance(random.uniform(0.9,1.1))\n",
    "    if random.random() < 0.4:\n",
    "        im = ImageEnhance.Contrast(im).enhance(random.uniform(0.9,1.1))\n",
    "    if random.random() < 0.35:\n",
    "        w,h = im.size\n",
    "        cx = random.uniform(0.92,1.0); cy = random.uniform(0.92,1.0)\n",
    "        nw,nh = max(1,int(w*cx)), max(1,int(h*cy))\n",
    "        left = random.randint(0, max(0, w-nw)); top = random.randint(0, max(0, h-nh))\n",
    "        im = im.crop((left,top,left+nw,top+nh)).resize((w,h), Image.LANCZOS)\n",
    "    try:\n",
    "        im.save(dst_path, quality=92)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# ---------- compute dynamic TARGET = largest current class size ----------\n",
    "class_dirs = sorted([p for p in dataset_root.iterdir() if p.is_dir()])\n",
    "orig_counts = {}\n",
    "for d in class_dirs:\n",
    "    orig_counts[d.name] = len(list_image_files(d))\n",
    "\n",
    "if len(orig_counts) == 0:\n",
    "    raise RuntimeError(\"No class folders found under dataset root.\")\n",
    "\n",
    "TARGET = max(orig_counts.values())\n",
    "print(f\"Computed dynamic TARGET (max class size) = {TARGET}\")\n",
    "\n",
    "# ---------- process ----------\n",
    "augmentation_stats = []\n",
    "all_paths = []\n",
    "\n",
    "print(f\"\\nFound {len(class_dirs)} class folders. Augmenting classes with < {TARGET} images to reach {TARGET} per class...\\n\")\n",
    "\n",
    "for class_dir in tqdm(class_dirs, desc=\"Classes\"):\n",
    "    class_name = class_dir.name\n",
    "    disp_name = display_name_from_folder(class_name)\n",
    "    files = list_image_files(class_dir)\n",
    "    original_count = len(files)\n",
    "\n",
    "    # compute highest numeric token anywhere in filenames\n",
    "    max_num = 0\n",
    "    for f in files:\n",
    "        n = max_number_in_filename(f.name)\n",
    "        if n and n > max_num:\n",
    "            max_num = n\n",
    "    if max_num == 0:\n",
    "        max_num = original_count\n",
    "\n",
    "    start_seq = max_num + 1\n",
    "\n",
    "    # avoid colliding with existing <Disp>_Aug_<n> files\n",
    "    existing_aug_nums = set()\n",
    "    for f in files:\n",
    "        if SYN_MARK in f.stem:\n",
    "            try:\n",
    "                part = f.stem.split(SYN_MARK)[-1]\n",
    "                existing_aug_nums.add(int(part))\n",
    "            except:\n",
    "                pass\n",
    "    while start_seq in existing_aug_nums:\n",
    "        start_seq += 1\n",
    "\n",
    "    # Only add images for classes that are below TARGET (no changes for classes >= TARGET)\n",
    "    needed = max(0, TARGET - original_count)\n",
    "    synthetic_created = 0\n",
    "\n",
    "    # prefer original images as source (exclude existing Aug when picking source)\n",
    "    source_pool = [p for p in files if SYN_MARK not in p.stem and not p.name.startswith(\"syn_\")]\n",
    "    if len(source_pool) == 0:\n",
    "        source_pool = files\n",
    "    if len(source_pool) == 0:\n",
    "        print(f\"‚ö†Ô∏è Skipping {class_name} ‚Äî no source images.\")\n",
    "        augmentation_stats.append({'class': class_name, 'original': original_count, 'synthetic': 0, 'total': original_count})\n",
    "        all_paths.extend([str(p) for p in files])\n",
    "        continue\n",
    "\n",
    "    seq = start_seq\n",
    "    attempts = 0\n",
    "    # reasonable attempts cap to avoid infinite loop; increases with needed\n",
    "    max_attempts = max(2000, needed * 6)\n",
    "    while synthetic_created < needed and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        src = random.choice(source_pool)\n",
    "        new_fname = f\"{disp_name}{SYN_MARK}{seq}.jpg\"\n",
    "        dst = class_dir / new_fname\n",
    "        if dst.exists():\n",
    "            seq += 1\n",
    "            continue\n",
    "        ok = augment_image_save(src, dst)\n",
    "        if ok:\n",
    "            synthetic_created += 1\n",
    "            seq += 1\n",
    "        else:\n",
    "            try:\n",
    "                shutil.copy(src, dst)\n",
    "                synthetic_created += 1\n",
    "                seq += 1\n",
    "            except Exception:\n",
    "                seq += 1\n",
    "                continue\n",
    "\n",
    "    final_files = list_image_files(class_dir)\n",
    "    total_after = len(final_files)\n",
    "    augmentation_stats.append({'class': class_name, 'original': original_count, 'synthetic': synthetic_created, 'total': total_after})\n",
    "    all_paths.extend([str(p) for p in final_files])\n",
    "\n",
    "# ---------- save report & paths ----------\n",
    "if augmentation_stats:\n",
    "    aug_df = pd.DataFrame(augmentation_stats).sort_values('class').reset_index(drop=True)\n",
    "    aug_df.to_csv(augmentation_report_csv, index=False)\n",
    "    print(\"\\n‚úÖ augmentation_report.csv saved.\")\n",
    "    print(aug_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è No augmentation stats recorded.\")\n",
    "\n",
    "np_paths = np.array(all_paths, dtype=object)\n",
    "np.save(paths_augmented_file, np_paths)\n",
    "print(f\"\\n‚úÖ Updated paths list saved to: {paths_augmented_file}  (len={len(np_paths)})\")\n",
    "\n",
    "# ---------- final summary ----------\n",
    "counts = {r['class']: r['total'] for r in augmentation_stats}\n",
    "min_c = min(counts.values()) if counts else 0\n",
    "max_c = max(counts.values()) if counts else 0\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä NEW BALANCE STATUS (images on disk)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Min per class: {min_c}\")\n",
    "print(f\"Max per class: {max_c}\")\n",
    "print(f\"Target: {TARGET}\")\n",
    "if min_c >= TARGET and max_c <= TARGET:\n",
    "    print(\"‚úÖ All classes reached TARGET.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some classes may still be below TARGET ‚Äî inspect augmentation_report.csv\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "233ff06619a7e6d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:03:13.741272Z",
     "start_time": "2025-11-15T17:03:13.720493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT: human_face_dataset/pins_face_recognition\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 1 ‚Äî Configuration Block (edit only DATA_ROOT)\n",
    "# Directory/Path Define\n",
    "\n",
    "DATA_ROOT = \"human_face_dataset/pins_face_recognition\"  # << set this to your dataset folder (one subfolder per person)\n",
    "# Block 1 ‚Äî Imports & configuration\n",
    "from pathlib import Path\n",
    "import os, time, pickle, hashlib\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- EDIT IF NEEDED ----------\n",
    "# Set DATA_ROOT to the folder that contains one folder per person (images inside)\n",
    "DATA_ROOT = \"human_face_dataset/pins_face_recognition\"\n",
    "# ------------------------------------\n",
    "\n",
    "# Cache & artifact locations\n",
    "CACHE_DIR = Path('./embeddings_cache'); CACHE_DIR.mkdir(exist_ok=True)\n",
    "EMB_FILE = CACHE_DIR / 'X_emb.npy'\n",
    "LBL_FILE = CACHE_DIR / 'y_lbl.npy'\n",
    "PATHS_FILE = CACHE_DIR / 'paths.npy'\n",
    "CLF_FILE = CACHE_DIR / 'svc_model_retrained.pkl'\n",
    "CENTROIDS_FILE = CACHE_DIR / 'centroids.npy'\n",
    "CLASSES_FILE = CACHE_DIR / 'classes.npy'\n",
    "\n",
    "# Image extensions considered\n",
    "EXTS = {'.jpg', '.jpeg', '.png'}\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db18630037bcc4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:03:20.835247Z",
     "start_time": "2025-11-15T17:03:18.099887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready. Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Block 2 ‚Äî Imports and Model initialization (facenet-pytorch)\n",
    "try:\n",
    "    from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "    import torch\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Missing packages. Run pip install facenet-pytorch torch torchvision opencv-python scikit-learn tqdm matplotlib pillow\") from e\n",
    "\n",
    "device = 'cpu'\n",
    "mtcnn = MTCNN(keep_all=False, device=device)          # detector + alignment\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()  # embedding model (512-d)\n",
    "print(\"Models ready. Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604129ddedddc451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:03:24.711123Z",
     "start_time": "2025-11-15T17:03:24.668079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 0 duplicate files to duplicates. Kept first occurrence of each duplicated image.\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 3: Move duplicate files into ./duplicates/ (safe)\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# `dupes` is the dict you produced mapping md5 -> [paths], or re-find below\n",
    "def find_duplicates(paths):\n",
    "    import hashlib\n",
    "    from collections import defaultdict\n",
    "    def h(p):\n",
    "        m = hashlib.md5()\n",
    "        with open(p,'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(8192), b''):\n",
    "                m.update(chunk)\n",
    "        return m.hexdigest()\n",
    "    D = defaultdict(list)\n",
    "    for p in paths:\n",
    "        D[h(p)].append(p)\n",
    "    return {k:v for k,v in D.items() if len(v)>1}\n",
    "\n",
    "# Build paths list (adjust root)\n",
    "root = Path(r'D:\\DATA_SCIENCE\\My_Projects\\testing\\human_face_identify\\pins_face_recognition')\n",
    "paths = [str(p) for p in root.rglob('*') if p.suffix.lower() in ('.jpg','.jpeg','.png')]\n",
    "dupes = find_duplicates(paths)\n",
    "\n",
    "outdir = Path('./duplicates'); outdir.mkdir(exist_ok=True)\n",
    "moved = 0\n",
    "for h, lst in dupes.items():\n",
    "    keep = lst[0]            # keep first occurrence\n",
    "    for p in lst[1:]:\n",
    "        target = outdir / Path(p).name\n",
    "        # avoid name collisions\n",
    "        i = 1\n",
    "        while target.exists():\n",
    "            target = outdir / f\"{Path(p).stem}_{i}{Path(p).suffix}\"\n",
    "            i += 1\n",
    "        shutil.move(p, str(target))\n",
    "        moved += 1\n",
    "print(f\"Moved {moved} duplicate files to {outdir}. Kept first occurrence of each duplicated image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422b28985f22a97f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:03:30.145326Z",
     "start_time": "2025-11-15T17:03:29.001790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: 105 Total images: 24885\n",
      "Saved paths to embeddings_cache\\paths.npy\n"
     ]
    }
   ],
   "source": [
    "# Block 4 ‚Äî Data Count & Define Image Path for the operation\n",
    "# Build image_paths and labels and save to cache (paths.npy)\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT = Path(DATA_ROOT)\n",
    "image_paths = [str(p) for p in sorted(ROOT.rglob('*')) if p.suffix.lower() in EXTS]\n",
    "labels = [Path(p).parent.name for p in image_paths]\n",
    "print(\"Classes found:\", len(set(labels)), \"Total images:\", len(image_paths))\n",
    "# Save list of paths to allow deduping later or resume\n",
    "np.save(PATHS_FILE, np.array(image_paths, dtype=object))\n",
    "print(\"Saved paths to\", PATHS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4749f6e553528c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:03:33.529382Z",
     "start_time": "2025-11-15T17:03:33.301013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from cache: 24885 embeddings loaded.\n",
      "No new images to process.\n"
     ]
    }
   ],
   "source": [
    "# Block 5.1: (Embedding Block)\n",
    "# Batched, resumable extraction to EMB_FILE / LBL_FILE (overwrite/resume)\n",
    "\n",
    "import numpy as np, torch\n",
    "from PIL import Image\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# parameters: tune for your machine\n",
    "BATCH_SIZE = 48     # try 16/32/48/64 depending on RAM\n",
    "SAVE_EVERY = 1      # save after this many batches\n",
    "MAX_SIDE = 640      # resize max side for speed; lower to 480 if needed\n",
    "\n",
    "# load list of all paths\n",
    "image_paths = list(np.load(PATHS_FILE, allow_pickle=True))\n",
    "n_total = len(image_paths)\n",
    "\n",
    "# resume from cache if exists\n",
    "if EMB_FILE.exists() and LBL_FILE.exists():\n",
    "    X_cached = np.load(EMB_FILE)\n",
    "    y_cached = np.load(LBL_FILE, allow_pickle=True)\n",
    "    start_idx = len(y_cached)\n",
    "    X_list = [X_cached[i] for i in range(len(X_cached))]\n",
    "    y_list = [y_cached[i] for i in range(len(y_cached))]\n",
    "    print(f\"Resuming from cache: {start_idx} embeddings loaded.\")\n",
    "else:\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    start_idx = 0\n",
    "\n",
    "def safe_open_resize(path, max_side=MAX_SIDE):\n",
    "    try:\n",
    "        im = Image.open(path).convert('RGB')\n",
    "        w,h = im.size\n",
    "        s = max(w,h)\n",
    "        if s > max_side:\n",
    "            scale = max_side / s\n",
    "            im = im.resize((int(w*scale), int(h*scale)), Image.BILINEAR)\n",
    "        return im\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "pairs = image_paths[start_idx:]\n",
    "n = len(pairs)\n",
    "if n == 0:\n",
    "    print(\"No new images to process.\")\n",
    "else:\n",
    "    n_batches = ceil(n / BATCH_SIZE)\n",
    "    print(f\"Processing {n} images in {n_batches} batches (batch_size={BATCH_SIZE})\")\n",
    "    bad_files = []\n",
    "    batch_count = 0\n",
    "    t_total = time.time()\n",
    "    for b in tqdm(range(n_batches), desc='Batches'):\n",
    "        s = b * BATCH_SIZE\n",
    "        e = min(s + BATCH_SIZE, n)\n",
    "        batch_paths = pairs[s:e]\n",
    "        pil_imgs = []\n",
    "        pil_labels = []\n",
    "        real_paths = []\n",
    "        for path in batch_paths:\n",
    "            im = safe_open_resize(path)\n",
    "            if im is None:\n",
    "                bad_files.append(path)\n",
    "                continue\n",
    "            pil_imgs.append(im)\n",
    "            pil_labels.append(Path(path).parent.name)\n",
    "            real_paths.append(path)\n",
    "        if not pil_imgs:\n",
    "            batch_count += 1\n",
    "            continue\n",
    "\n",
    "        # try batch detection; fallback to per-image if needed\n",
    "        faces = None\n",
    "        try:\n",
    "            faces = mtcnn(pil_imgs)\n",
    "        except Exception as ex:\n",
    "            faces = None\n",
    "            # fallback will run below\n",
    "\n",
    "        face_tensors = []\n",
    "        valid_labels = []\n",
    "        if isinstance(faces, torch.Tensor):\n",
    "            # tensor -> all faces detected and aligned\n",
    "            for i in range(faces.shape[0]):\n",
    "                f = faces[i].unsqueeze(0)\n",
    "                face_tensors.append(f)\n",
    "                valid_labels.append(pil_labels[i])\n",
    "        else:\n",
    "            # fallback to per-image detection\n",
    "            for im, lab, path in zip(pil_imgs, pil_labels, real_paths):\n",
    "                try:\n",
    "                    f = mtcnn(im)\n",
    "                    if f is None:\n",
    "                        bad_files.append(path)\n",
    "                        continue\n",
    "                    if f.dim() == 3:\n",
    "                        f = f.unsqueeze(0)\n",
    "                    face_tensors.append(f)\n",
    "                    valid_labels.append(lab)\n",
    "                except Exception:\n",
    "                    bad_files.append(path)\n",
    "                    continue\n",
    "\n",
    "        if not face_tensors:\n",
    "            batch_count += 1\n",
    "            if batch_count % SAVE_EVERY == 0 and len(y_list) > 0:\n",
    "                np.save(EMB_FILE, np.vstack(X_list))\n",
    "                np.save(LBL_FILE, np.array(y_list, dtype=object))\n",
    "            continue\n",
    "\n",
    "        face_batch = torch.cat(face_tensors, dim=0)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                emb_batch = resnet(face_batch).cpu().numpy()\n",
    "        except Exception:\n",
    "            # per-item embedding fallback\n",
    "            emb_batch = []\n",
    "            for ft in face_tensors:\n",
    "                try:\n",
    "                    with torch.no_grad():\n",
    "                        e = resnet(ft).cpu().numpy().reshape(-1)\n",
    "                    emb_batch.append(e)\n",
    "                except Exception:\n",
    "                    emb_batch.append(None)\n",
    "            filtered = [(e, lab) for e, lab in zip(emb_batch, valid_labels) if e is not None]\n",
    "            if not filtered:\n",
    "                batch_count += 1\n",
    "                continue\n",
    "            emb_batch = np.vstack([f[0] for f in filtered])\n",
    "            valid_labels = [f[1] for f in filtered]\n",
    "\n",
    "        for emb, lab in zip(emb_batch, valid_labels):\n",
    "            X_list.append(emb.astype('float32'))\n",
    "            y_list.append(lab)\n",
    "\n",
    "        batch_count += 1\n",
    "        if batch_count % SAVE_EVERY == 0:\n",
    "            np.save(EMB_FILE, np.vstack(X_list))\n",
    "            np.save(LBL_FILE, np.array(y_list, dtype=object))\n",
    "            t_elapsed = time.time() - t_total\n",
    "            processed = len(y_list)\n",
    "            rate = processed / t_elapsed if t_elapsed > 0 else 0\n",
    "            print(f\"Saved cache: {len(y_list)} embeddings; rate {rate:.2f} emb/s\")\n",
    "\n",
    "    # final save\n",
    "    if len(X_list) > 0:\n",
    "        X = np.vstack(X_list).astype('float32')\n",
    "        y = np.array(y_list, dtype=object)\n",
    "        np.save(EMB_FILE, X)\n",
    "        np.save(LBL_FILE, y)\n",
    "        np.save(PATHS_FILE, np.array(image_paths, dtype=object))  # ensure paths saved\n",
    "        print(\"Done. Extracted embeddings:\", X.shape)\n",
    "    else:\n",
    "        print(\"No embeddings extracted in this run.\")\n",
    "\n",
    "    if bad_files:\n",
    "        bad_txt = CACHE_DIR / 'bad_files.txt'\n",
    "        with open(bad_txt, 'w', encoding='utf-8') as f:\n",
    "            for p in sorted(set(bad_files)):\n",
    "                f.write(p + \"\\n\")\n",
    "        print(f\"{len(set(bad_files))} problematic files logged to {bad_txt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23ddd4e4e77f79c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:04:27.051120Z",
     "start_time": "2025-11-15T17:03:43.561117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (24885, 512) 24885\n",
      "Unique images: 24878 of 24885\n",
      "Saved deduplicated embeddings to embeddings_cache/*.\n"
     ]
    }
   ],
   "source": [
    "# Block 5.2 ‚Äî deduplicate embeddings using file MD5 (optional)\n",
    "if not EMB_FILE.exists() or not PATHS_FILE.exists():\n",
    "    print(\"Embeddings or paths missing. Run Block 5 first.\")\n",
    "else:\n",
    "    X = np.load(EMB_FILE)\n",
    "    y = np.load(LBL_FILE, allow_pickle=True)\n",
    "    paths = list(np.load(PATHS_FILE, allow_pickle=True))\n",
    "    print(\"Loaded:\", X.shape, len(paths))\n",
    "    seen = {}\n",
    "    keep_idx = []\n",
    "    for i, p in enumerate(paths):\n",
    "        try:\n",
    "            h = hashlib.md5(open(p, 'rb').read()).hexdigest()\n",
    "        except Exception:\n",
    "            continue\n",
    "        if h in seen:\n",
    "            continue\n",
    "        seen[h] = i\n",
    "        keep_idx.append(i)\n",
    "    print(\"Unique images:\", len(keep_idx), \"of\", len(paths))\n",
    "    X_new = X[keep_idx]\n",
    "    y_new = y[keep_idx]\n",
    "    paths_new = [paths[i] for i in keep_idx]\n",
    "    np.save(CACHE_DIR / 'X_emb_dedup.npy', X_new)\n",
    "    np.save(CACHE_DIR / 'y_lbl_dedup.npy', y_new)\n",
    "    np.save(CACHE_DIR / 'paths_dedup.npy', np.array(paths_new, dtype=object))\n",
    "    print(\"Saved deduplicated embeddings to embeddings_cache/*.\")\n",
    "    # If you want to use deduped files as main, replace originals (manual step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8fe5811d5d15f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:04:32.546069Z",
     "start_time": "2025-11-15T17:04:32.395473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: embeddings_cache/X_emb.npy embeddings_cache/y_lbl.npy len= 24885\n"
     ]
    }
   ],
   "source": [
    "# Force evaluation block to use augmented artifacts (minimal lines)\n",
    "import os, numpy as np\n",
    "\n",
    "paths = np.load(\"embeddings_cache/paths_augmented.npy\", allow_pickle=True)\n",
    "\n",
    "X_file = \"embeddings_cache/X_emb_augmented.npy\" if os.path.exists(\"embeddings_cache/X_emb_augmented.npy\") else \"embeddings_cache/X_emb.npy\"\n",
    "y_file = \"embeddings_cache/y_lbl_augmented.npy\" if os.path.exists(\"embeddings_cache/y_lbl_augmented.npy\") else \"embeddings_cache/y_lbl.npy\"\n",
    "\n",
    "X = np.load(X_file, allow_pickle=True)   # embeddings\n",
    "y = np.load(y_file, allow_pickle=True)   # labels\n",
    "\n",
    "# also set common alternate names used elsewhere\n",
    "X_emb = X; X_embedded = X\n",
    "y_lbl = y; labels = y\n",
    "paths = paths\n",
    "print(\"Using:\", X_file, y_file, \"len=\", len(paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c84a770c4da010c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:10:45.757221Z",
     "start_time": "2025-11-15T17:10:33.716073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä CLASS BALANCE ANALYSIS\n",
      "================================================================================\n",
      "Total classes: 105\n",
      "Total samples: 24885\n",
      "Min samples per class: 237\n",
      "Max samples per class: 237\n",
      "Mean samples per class: 237.0\n",
      "Median samples per class: 237.0\n",
      "Imbalance ratio: 1.00x\n",
      "\n",
      "‚úÖ Dataset is BALANCED (ratio 1.00x ‚â§ 1.5x)\n",
      "\n",
      "================================================================================\n",
      "üìâ CLASSES WITH FEWEST SAMPLES (Bottom 10)\n",
      "================================================================================\n",
      "  pins_Adriana Lima: 237 samples\n",
      "  pins_Alex Lawther: 237 samples\n",
      "  pins_Alexandra Daddario: 237 samples\n",
      "  pins_Alvaro Morte: 237 samples\n",
      "  pins_alycia dabnem carey: 237 samples\n",
      "  pins_Amanda Crew: 237 samples\n",
      "  pins_amber heard: 237 samples\n",
      "  pins_Andy Samberg: 237 samples\n",
      "  pins_Anne Hathaway: 237 samples\n",
      "  pins_Anthony Mackie: 237 samples\n",
      "\n",
      "================================================================================\n",
      "üìà CLASSES WITH MOST SAMPLES (Top 10)\n",
      "================================================================================\n",
      "  pins_tom ellis: 237 samples\n",
      "  pins_Tom Hardy: 237 samples\n",
      "  pins_Tom Hiddleston: 237 samples\n",
      "  pins_Tom Holland: 237 samples\n",
      "  pins_Tuppence Middleton: 237 samples\n",
      "  pins_Ursula Corbero: 237 samples\n",
      "  pins_Wentworth Miller: 237 samples\n",
      "  pins_Zac Efron: 237 samples\n",
      "  pins_Zendaya: 237 samples\n",
      "  pins_Zoe Saldana: 237 samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "jetTransient": {
      "display_id": null
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Distribution plot saved as: class_distribution.png\n",
      "================================================================================\n",
      "‚úÖ Detailed balance report saved as: class_balance_report.csv\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Block 6A - Analysis of Dataset Balance (After Augmentation)\n",
    "################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) Load the CLEAN augmented path list\n",
    "# ---------------------------------------------------------\n",
    "paths = np.load(\"embeddings_cache/paths_augmented.npy\", allow_pickle=True)\n",
    "\n",
    "# Extract class names from folder names\n",
    "class_names = [Path(p).parent.name for p in paths]\n",
    "y = np.array(class_names)\n",
    "\n",
    "# Create class counts\n",
    "class_counts = Counter(class_names)\n",
    "\n",
    "# Sorted (needed for bottom/top 10 display)\n",
    "class_counts_sorted = sorted(class_counts.items(), key=lambda x: x[1])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) Compute statistics\n",
    "# ---------------------------------------------------------\n",
    "min_samples = min(class_counts.values())\n",
    "max_samples = max(class_counts.values())\n",
    "mean_samples = np.mean(list(class_counts.values()))\n",
    "median_samples = np.median(list(class_counts.values()))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä CLASS BALANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total classes: {len(class_counts)}\")\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "print(f\"Min samples per class: {min_samples}\")\n",
    "print(f\"Max samples per class: {max_samples}\")\n",
    "print(f\"Mean samples per class: {mean_samples:.1f}\")\n",
    "print(f\"Median samples per class: {median_samples:.1f}\")\n",
    "print(f\"Imbalance ratio: {max_samples/min_samples:.2f}x\")\n",
    "\n",
    "# Balance threshold\n",
    "BALANCE_THRESHOLD = 1.5\n",
    "IS_BALANCED = (max_samples / min_samples) <= BALANCE_THRESHOLD\n",
    "\n",
    "if IS_BALANCED:\n",
    "    print(f\"\\n‚úÖ Dataset is BALANCED (ratio {max_samples/min_samples:.2f}x ‚â§ {BALANCE_THRESHOLD}x)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Dataset is IMBALANCED (ratio {max_samples/min_samples:.2f}x > {BALANCE_THRESHOLD}x)\")\n",
    "    print(\"   Augmentation recommended! Run Block 6B below.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Show classes with lowest counts\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìâ CLASSES WITH FEWEST SAMPLES (Bottom 10)\")\n",
    "print(\"=\"*80)\n",
    "for class_name, count in class_counts_sorted[:10]:\n",
    "    print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4) Show classes with highest counts\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà CLASSES WITH MOST SAMPLES (Top 10)\")\n",
    "print(\"=\"*80)\n",
    "for class_name, count in class_counts_sorted[-10:]:\n",
    "    print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5) Visualization\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(15, 5))\n",
    "counts = [count for _, count in class_counts_sorted]\n",
    "plt.bar(range(len(counts)), counts, color='skyblue', edgecolor='black')\n",
    "plt.axhline(y=mean_samples, color='red', linestyle='--', label=f'Mean: {mean_samples:.1f}')\n",
    "plt.axhline(y=median_samples, color='green', linestyle='--', label=f'Median: {median_samples:.1f}')\n",
    "plt.xlabel('Class Index (sorted by count)')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Samples per Class Distribution')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Distribution plot saved as: class_distribution.png\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6) Save balance report as CSV\n",
    "# ---------------------------------------------------------\n",
    "balance_report = []\n",
    "for class_name, count in sorted(class_counts.items()):\n",
    "    balance_report.append({\n",
    "        'class': class_name,\n",
    "        'samples': count,\n",
    "        'percentage': f\"{count/len(y)*100:.2f}%\",\n",
    "        'status': '‚úì Good' if count >= mean_samples*0.7 else '‚ö† Low'\n",
    "    })\n",
    "\n",
    "balance_df = pd.DataFrame(balance_report)\n",
    "balance_df.to_csv('class_balance_report.csv', index=False)\n",
    "print(f\"‚úÖ Detailed balance report saved as: class_balance_report.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3021dac3d1b4de82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:11:08.586976Z",
     "start_time": "2025-11-15T17:11:08.483545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "üîÑ SMART AUGMENTATION (Embedding-Level)\n",
      "================================================================================\n",
      "‚úÖ Loaded embeddings X from variable 'X'\n",
      "‚úÖ Loaded labels y from variable 'y'\n",
      "‚úÖ Loaded 'paths' from variable 'paths'\n",
      "‚úÖ Dataset is balanced. Skipping augmentation.\n",
      "\n",
      "‚úÖ No augmentation performed. Dataset is already balanced!\n",
      "   You can proceed directly to Block 7 (training).\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Block 6B - Smart Augmentation (Embedding-Level) (cache-aware incremental augment)\n",
    "# Only run If Block A Is not run\n",
    "################################################################################\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"üîÑ SMART AUGMENTATION (Embedding-Level)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ---- imports ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "\n",
    "# ---- Helpers: locate CACHE_DIR (try existing variable else default) ----\n",
    "try:\n",
    "    CACHE_DIR\n",
    "except NameError:\n",
    "    CACHE_DIR = Path('embeddings_cache')\n",
    "CACHE_DIR = Path(CACHE_DIR)\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# candidate paths (try to preserve earlier names if present in workspace)\n",
    "emb_cache = CACHE_DIR / 'X_emb_augmented.npy'\n",
    "lbl_cache = CACHE_DIR / 'y_lbl_augmented.npy'\n",
    "paths_cache = CACHE_DIR / 'paths_augmented.npy'\n",
    "augmentation_report_csv = Path('augmentation_report.csv')\n",
    "\n",
    "# Try loading embeddings/labels/paths either from workspace variables or files\n",
    "def _load_var_or_file(varnames, candidates, label):\n",
    "    g = globals()\n",
    "    for n in varnames:\n",
    "        if n in g and g[n] is not None:\n",
    "            return g[n], f\"variable '{n}'\"\n",
    "    for c in candidates:\n",
    "        if c is None:\n",
    "            continue\n",
    "        p = Path(c)\n",
    "        if p.exists():\n",
    "            val = np.load(p, allow_pickle=True)\n",
    "            return val, f\"file: {p}\"\n",
    "    raise NameError(f\"{label} not found (tried vars {varnames} and files {candidates})\")\n",
    "\n",
    "# Attempt to find X, y, paths in globals or in common files\n",
    "emb_candidates = [emb_cache, 'X_emb.npy', 'X.npy', 'embeddings.npy']\n",
    "lbl_candidates = [lbl_cache, 'y_lbl.npy', 'y.npy', 'labels.npy']\n",
    "paths_candidates = [paths_cache, 'paths.npy']\n",
    "\n",
    "try:\n",
    "    X, X_source = _load_var_or_file(['X', 'X_emb', 'embeddings', 'embs'], emb_candidates, \"embeddings (X)\")\n",
    "    print(f\"‚úÖ Loaded embeddings X from {X_source}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(str(e) + \"\\nMake sure embeddings exist in memory as X or as a file.\") from None\n",
    "\n",
    "try:\n",
    "    y, y_source = _load_var_or_file(['y', 'y_lbl', 'labels', 'y_labels'], lbl_candidates, \"labels (y)\")\n",
    "    print(f\"‚úÖ Loaded labels y from {y_source}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(str(e) + \"\\nMake sure labels exist in memory as y or as a file.\") from None\n",
    "\n",
    "try:\n",
    "    paths, paths_source = _load_var_or_file(['paths', 'img_paths', 'paths_arr'], paths_candidates, \"paths\")\n",
    "    print(f\"‚úÖ Loaded 'paths' from {paths_source}\")\n",
    "except Exception:\n",
    "    # fallback: create dummy paths (so code runs)\n",
    "    n_items = len(y) if 'y' in globals() else len(X)\n",
    "    paths = np.array([f\"idx_{i}\" for i in range(n_items)], dtype=object)\n",
    "    print(\"‚ö†Ô∏è 'paths' not found ‚Äî created placeholder path names.\")\n",
    "\n",
    "# ---- compute current class stats (base dataset) ----\n",
    "unique_classes, counts = np.unique(y, return_counts=True)\n",
    "min_samples = int(counts.min())\n",
    "max_samples = int(counts.max())\n",
    "imb_ratio = max_samples / min_samples\n",
    "IS_BALANCED = imb_ratio <= 1.5\n",
    "\n",
    "if not IS_BALANCED:\n",
    "    print(\"‚ö†Ô∏è Your dataset is imbalanced. Proceeding with augmentation...\")\n",
    "    PROCEED_WITH_AUGMENTATION = True\n",
    "else:\n",
    "    print(\"‚úÖ Dataset is balanced. Skipping augmentation.\")\n",
    "    PROCEED_WITH_AUGMENTATION = False\n",
    "\n",
    "if PROCEED_WITH_AUGMENTATION:\n",
    "    # ---- configuration / performance ----\n",
    "    TARGET_SAMPLES = max_samples              # dynamic: balance to current max class size\n",
    "    MIN_SAMPLES_FOR_AUGMENT = 150             # informational only\n",
    "    AUG_BATCH = 128                           # batch size for synthetic generation\n",
    "    NOISE_STD = 0.01                          # gaussian noise stddev added to synthetic\n",
    "    print(f\"üéØ Target: {TARGET_SAMPLES} samples per class  (dynamic)\")\n",
    "    print(f\"üìä Current range: {min_samples} - {max_samples} samples\")\n",
    "    print(f\"üîß Will augment classes with < {TARGET_SAMPLES} samples (actual target)\")\n",
    "\n",
    "    # If augmented cache exists, load it. We will check its balance and possibly incrementally augment.\n",
    "    if emb_cache.exists() and lbl_cache.exists() and paths_cache.exists():\n",
    "        print(\"‚è±Ô∏è Augmented cache detected ‚Äî loading augmented artifacts from cache.\")\n",
    "        X_augmented = np.load(emb_cache, allow_pickle=True)\n",
    "        y_augmented = np.load(lbl_cache, allow_pickle=True)\n",
    "        paths_augmented = np.load(paths_cache, allow_pickle=True)\n",
    "\n",
    "        # Compute balance on cached augmented data\n",
    "        cached_counts = Counter(y_augmented)\n",
    "        cached_min = min(cached_counts.values())\n",
    "        cached_max = max(cached_counts.values())\n",
    "        print(f\"\\nCached augmented data range: {cached_min} - {cached_max} samples (imbalance {cached_max/cached_min:.2f}x)\")\n",
    "\n",
    "        # If cache is already fully balanced to TARGET_SAMPLES, skip. Otherwise do incremental augmentation.\n",
    "        if cached_min >= TARGET_SAMPLES and cached_max <= TARGET_SAMPLES:\n",
    "            print(\"‚úÖ Cached augmented dataset already meets TARGET_SAMPLES for all classes. No further augmentation required.\")\n",
    "        else:\n",
    "            # We'll only generate the missing samples per class to reach TARGET_SAMPLES\n",
    "            print(\"üîÅ Cached dataset still imbalanced vs TARGET_SAMPLES ‚Äî performing incremental augmentation for missing classes...\")\n",
    "            incremental_stats = []\n",
    "\n",
    "            # Build a dictionary mapping class -> current count in cached set\n",
    "            class_to_count = {c: cached_counts.get(c, 0) for c in unique_classes}\n",
    "\n",
    "            # For speed, convert X_augmented to list for append, same for labels/paths\n",
    "            X_list = list(X_augmented)\n",
    "            y_list = list(y_augmented)\n",
    "            paths_list = list(paths_augmented)\n",
    "\n",
    "            for class_name in tqdm(unique_classes, desc='Processing classes for incremental augmentation'):\n",
    "                current = class_to_count.get(class_name, 0)\n",
    "                if current >= TARGET_SAMPLES:\n",
    "                    continue  # already enough\n",
    "                needed = TARGET_SAMPLES - current\n",
    "                synthetic_count = 0\n",
    "\n",
    "                # Get originals for this class from the original X,y (not from cache) ‚Äî better variation\n",
    "                mask_orig = (y == class_name)\n",
    "                orig_embs = X[mask_orig]\n",
    "                if len(orig_embs) == 0:\n",
    "                    # if original dataset had 0, fallback to using class embeddings from cached set\n",
    "                    mask_cache = (y_augmented == class_name)\n",
    "                    orig_embs = X_augmented[mask_cache]\n",
    "                    if len(orig_embs) == 0:\n",
    "                        print(f\"‚ö†Ô∏è No originals found for class '{class_name}' in either original or cached data. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                emb_indices = np.arange(len(orig_embs))\n",
    "                synth_idx = 0\n",
    "\n",
    "                while synthetic_count < needed:\n",
    "                    batch = int(min(AUG_BATCH, needed - synthetic_count))\n",
    "\n",
    "                    if len(emb_indices) == 1:\n",
    "                        idx1 = idx2 = np.zeros(batch, dtype=int)\n",
    "                    else:\n",
    "                        idx1 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "                        idx2 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "\n",
    "                    emb1 = orig_embs[idx1]\n",
    "                    emb2 = orig_embs[idx2]\n",
    "\n",
    "                    alphas = np.random.uniform(0.3, 0.7, size=(batch, 1))\n",
    "                    synthetics = alphas * emb1 + (1 - alphas) * emb2\n",
    "                    noise = np.random.normal(0.0, NOISE_STD, size=synthetics.shape)\n",
    "                    synthetics = synthetics + noise\n",
    "\n",
    "                    norms = np.linalg.norm(synthetics, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    synthetics = synthetics / norms\n",
    "\n",
    "                    for i in range(batch):\n",
    "                        X_list.append(synthetics[i].astype('float32'))\n",
    "                        y_list.append(class_name)\n",
    "                        paths_list.append(f\"incremental_synth_{class_name}_{synth_idx}\")\n",
    "                        synth_idx += 1\n",
    "\n",
    "                    synthetic_count += batch\n",
    "\n",
    "                incremental_stats.append({\n",
    "                    'class': class_name,\n",
    "                    'original_in_cache': current,\n",
    "                    'added': synthetic_count,\n",
    "                    'new_total': current + synthetic_count\n",
    "                })\n",
    "                # update cached count for this class so subsequent checks use updated value\n",
    "                class_to_count[class_name] = current + synthetic_count\n",
    "\n",
    "            # Convert lists back to arrays\n",
    "            X_augmented = np.array(X_list, dtype='float32')\n",
    "            y_augmented = np.array(y_list, dtype=object)\n",
    "            paths_augmented = np.array(paths_list, dtype=object)\n",
    "\n",
    "            # Update augmentation report: combine previous report (if exists) with incremental report\n",
    "            if augmentation_report_csv.exists():\n",
    "                try:\n",
    "                    prev_df = pd.read_csv(augmentation_report_csv)\n",
    "                except Exception:\n",
    "                    prev_df = pd.DataFrame()\n",
    "            else:\n",
    "                prev_df = pd.DataFrame()\n",
    "\n",
    "            if incremental_stats:\n",
    "                inc_df = pd.DataFrame(incremental_stats)\n",
    "                # If prev_df has same classes, add added counts to previous synthetic; otherwise concat\n",
    "                if not prev_df.empty:\n",
    "                    prev_df = prev_df.set_index('class')\n",
    "                    inc_df = inc_df.set_index('class')\n",
    "                    for cls in inc_df.index:\n",
    "                        if cls in prev_df.index:\n",
    "                            prev_row = prev_df.loc[cls].to_dict()\n",
    "                            # update synthetic & total\n",
    "                            prev_df.at[cls, 'synthetic'] = int(prev_df.at[cls, 'synthetic']) + int(inc_df.at[cls, 'added'])\n",
    "                            prev_df.at[cls, 'total'] = int(prev_df.at[cls, 'total']) + int(inc_df.at[cls, 'added'])\n",
    "                        else:\n",
    "                            prev_df = pd.concat([prev_df, pd.DataFrame({\n",
    "                                'original': [inc_df.at[cls, 'original_in_cache']],\n",
    "                                'synthetic': [inc_df.at[cls, 'added']],\n",
    "                                'total': [inc_df.at[cls, 'new_total']]\n",
    "                            }, index=[cls])])\n",
    "                    prev_df = prev_df.reset_index().rename(columns={'index': 'class'})\n",
    "                    final_report_df = prev_df\n",
    "                else:\n",
    "                    inc_df = inc_df.reset_index().rename(columns={'index': 'class'})\n",
    "                    final_report_df = inc_df\n",
    "                final_report_df.to_csv(augmentation_report_csv, index=False)\n",
    "                print(\"\\n‚úÖ Incremental augmentation completed and augmentation_report.csv updated.\")\n",
    "                try:\n",
    "                    print(final_report_df.to_string(index=False))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            else:\n",
    "                print(\"‚ÑπÔ∏è No incremental augmentation was needed (cache already met TARGET_SAMPLES).\")\n",
    "\n",
    "            # Save updated caches\n",
    "            np.save(emb_cache, X_augmented)\n",
    "            np.save(lbl_cache, y_augmented)\n",
    "            np.save(paths_cache, paths_augmented)\n",
    "            print(\"\\n‚úÖ Cache files updated with incremental augmentations.\")\n",
    "\n",
    "    else:\n",
    "        # No cache exists: perform full augmentation up to TARGET_SAMPLES (same approach as incremental)\n",
    "        print(\"üîÑ No augmented cache found ‚Äî generating full augmented dataset up to TARGET_SAMPLES...\")\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        paths_list = []\n",
    "        augmentation_stats = []\n",
    "\n",
    "        for class_name in tqdm(unique_classes, desc='Processing classes'):\n",
    "            mask_orig = (y == class_name)\n",
    "            orig_embs = X[mask_orig]\n",
    "            orig_paths = np.array(paths)[mask_orig]\n",
    "            current_count = len(orig_embs)\n",
    "\n",
    "            # add originals\n",
    "            X_list.extend(orig_embs)\n",
    "            y_list.extend([class_name] * current_count)\n",
    "            paths_list.extend(orig_paths.tolist())\n",
    "\n",
    "            if current_count < TARGET_SAMPLES:\n",
    "                needed_total = TARGET_SAMPLES - current_count\n",
    "                synthetic_count = 0\n",
    "                emb_indices = np.arange(len(orig_embs))\n",
    "                syn_idx = 0\n",
    "\n",
    "                if len(emb_indices) == 0:\n",
    "                    print(f\"‚ö†Ô∏è Class '{class_name}' has 0 originals ‚Äî skipping.\")\n",
    "                    continue\n",
    "\n",
    "                while synthetic_count < needed_total:\n",
    "                    batch = int(min(AUG_BATCH, needed_total - synthetic_count))\n",
    "\n",
    "                    if len(emb_indices) == 1:\n",
    "                        idx1 = idx2 = np.zeros(batch, dtype=int)\n",
    "                    else:\n",
    "                        idx1 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "                        idx2 = np.random.choice(emb_indices, size=batch, replace=True)\n",
    "\n",
    "                    emb1 = orig_embs[idx1]\n",
    "                    emb2 = orig_embs[idx2]\n",
    "\n",
    "                    alphas = np.random.uniform(0.3, 0.7, size=(batch, 1))\n",
    "                    synthetics = alphas * emb1 + (1 - alphas) * emb2\n",
    "                    noise = np.random.normal(0.0, NOISE_STD, size=synthetics.shape)\n",
    "                    synthetics = synthetics + noise\n",
    "\n",
    "                    norms = np.linalg.norm(synthetics, axis=1, keepdims=True)\n",
    "                    norms[norms == 0] = 1.0\n",
    "                    synthetics = synthetics / norms\n",
    "\n",
    "                    for i in range(batch):\n",
    "                        X_list.append(synthetics[i].astype('float32'))\n",
    "                        y_list.append(class_name)\n",
    "                        paths_list.append(f\"synthetic_{class_name}_{syn_idx}\")\n",
    "                        syn_idx += 1\n",
    "\n",
    "                    synthetic_count += batch\n",
    "\n",
    "                augmentation_stats.append({\n",
    "                    'class': class_name,\n",
    "                    'original': current_count,\n",
    "                    'synthetic': synthetic_count,\n",
    "                    'total': current_count + synthetic_count\n",
    "                })\n",
    "\n",
    "        # convert and save\n",
    "        X_augmented = np.array(X_list, dtype='float32')\n",
    "        y_augmented = np.array(y_list, dtype=object)\n",
    "        paths_augmented = np.array(paths_list, dtype=object)\n",
    "\n",
    "        np.save(emb_cache, X_augmented)\n",
    "        np.save(lbl_cache, y_augmented)\n",
    "        np.save(paths_cache, paths_augmented)\n",
    "\n",
    "        if augmentation_stats:\n",
    "            aug_df = pd.DataFrame(augmentation_stats)\n",
    "            aug_df.to_csv(augmentation_report_csv, index=False)\n",
    "            print(\"\\n‚úÖ Augmentation complete and report saved.\")\n",
    "            print(aug_df.to_string(index=False))\n",
    "        else:\n",
    "            print(\"\\n‚ÑπÔ∏è No augmentation stats recorded (unexpected if dataset was imbalanced).\")\n",
    "\n",
    "    # ---- report final balance status ----\n",
    "    new_counts = Counter(np.load(lbl_cache, allow_pickle=True))\n",
    "    new_min = min(new_counts.values())\n",
    "    new_max = max(new_counts.values())\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä NEW BALANCE STATUS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Min samples per class: {new_min}\")\n",
    "    print(f\"Max samples per class: {new_max}\")\n",
    "    print(f\"New imbalance ratio: {new_max/new_min:.2f}x\")\n",
    "\n",
    "    if new_max / new_min <= 1.5:\n",
    "        print(\"‚úÖ Dataset is now BALANCED!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Still some imbalance (consider increasing TARGET_SAMPLES or re-running augmentation)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìÅ AUGMENTED FILES SAVED:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚úÖ {emb_cache}\")\n",
    "    print(f\"‚úÖ {lbl_cache}\")\n",
    "    print(f\"‚úÖ {paths_cache}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è IMPORTANT: Update Block 7 (training) to use augmented files:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Change these lines in Block 7:\")\n",
    "    print(\"  FROM:\")\n",
    "    print(\"    EMB_SRC = EMB_FILE\")\n",
    "    print(\"    LBL_SRC = LBL_FILE\")\n",
    "    print(\"  TO:\")\n",
    "    print(\"    EMB_SRC = CACHE_DIR / 'X_emb_augmented.npy'\")\n",
    "    print(\"    LBL_SRC = CACHE_DIR / 'y_lbl_augmented.npy'\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚úÖ No augmentation performed. Dataset is already balanced!\")\n",
    "    print(\"   You can proceed directly to Block 7 (training).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "468a862bcf95cc63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:21:27.929239Z",
     "start_time": "2025-11-15T17:18:53.704574Z"
    }
   },
   "source": [
    "# Block 7 ‚Äî Training Block\n",
    "\n",
    "# (train classifier (SVM))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# choose embeddings source (deduped if you created them)\n",
    "EMB_SRC = CACHE_DIR / 'X_emb.npy'\n",
    "LBL_SRC = CACHE_DIR / 'y_lbl.npy'\n",
    "\n",
    "X = np.load(EMB_SRC)\n",
    "y = np.load(LBL_SRC, allow_pickle=True)\n",
    "print(\"Loaded embeddings:\", X.shape)\n",
    "\n",
    "le = LabelEncoder().fit(y); y_enc = le.transform(y)\n",
    "norm = Normalizer('l2'); Xn = norm.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, y_enc, stratify=y_enc, test_size=0.15, random_state=42)\n",
    "print(\"Train/test:\", X_train.shape, X_test.shape)\n",
    "\n",
    "clf = SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "t0 = time.time(); clf.fit(X_train, y_train)\n",
    "print(\"Trained SVM in {:.1f}s\".format(time.time()-t0))\n",
    "\n",
    "# Save classifier with consistent keys\n",
    "with open(CLF_FILE, 'wb') as f:\n",
    "    pickle.dump({'clf': clf, 'le': le, 'norm': norm, 'X_test': X_test, 'y_test': y_test}, f)\n",
    "print(\"Saved classifier to\", CLF_FILE)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: (24885, 512)\n",
      "Train/test: (21152, 512) (3733, 512)\n",
      "Trained SVM in 149.7s\n",
      "Saved classifier to embeddings_cache\\svc_model_retrained.pkl\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "6c7667e012d0c926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:51:45.483369Z",
     "start_time": "2025-11-15T17:38:06.169175Z"
    }
   },
   "source": [
    "# Block 8.1 ‚Äî Evaluation: classification report, confusion matrix, 5-fold CV, centroid baseline, threshold\n",
    "import pickle, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# load saved classifier\n",
    "obj = pickle.load(open(CLF_FILE, 'rb'))\n",
    "clf = obj['clf']; le = obj['le']; norm = obj['norm']\n",
    "X_test = obj['X_test']; y_test = obj['y_test']\n",
    "\n",
    "# report\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred).astype(float)\n",
    "cmn = cm / cm.sum(axis=1)[:, None]\n",
    "plt.figure(figsize=(8,8)); plt.imshow(cmn); plt.title('Normalized confusion matrix'); plt.colorbar(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 5-fold CV on full dataset\n",
    "X_all = np.load(EMB_FILE); y_all = np.load(LBL_FILE, allow_pickle=True)\n",
    "y_all_enc = le.transform(y_all); Xn_all = norm.transform(X_all)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "for tr, te in skf.split(Xn_all, y_all_enc):\n",
    "    clf.fit(Xn_all[tr], y_all_enc[tr])\n",
    "    accs.append(clf.score(Xn_all[te], y_all_enc[te]))\n",
    "print(\"5-fold CV: mean={:.4f} std={:.4f}\".format(np.mean(accs), np.std(accs)))\n",
    "\n",
    "# centroid baseline\n",
    "Xn_norm = normalize(X_all, axis=1)\n",
    "centroids = {c: Xn_norm[y_all_enc==c].mean(axis=0) for c in np.unique(y_all_enc)}\n",
    "# save centroids and classes for lightweight inference\n",
    "centroid_matrix = np.vstack([centroids[c] for c in sorted(centroids.keys())])\n",
    "classes_order = np.array([le.classes_[c] for c in sorted(centroids.keys())])\n",
    "np.save(CENTROIDS_FILE, centroid_matrix)\n",
    "np.save(CLASSES_FILE, classes_order)\n",
    "print(\"Saved centroids to\", CENTROIDS_FILE, \"and classes to\", CLASSES_FILE)\n",
    "\n",
    "# centroid accuracy on same test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "_, X_test_c, _, y_test_c = train_test_split(Xn_norm, y_all_enc, stratify=y_all_enc, test_size=0.15, random_state=42)\n",
    "def predict_centroid(emb):\n",
    "    emb = emb / np.linalg.norm(emb)\n",
    "    sims = centroid_matrix.dot(emb)\n",
    "    return sims.argmax(), sims.max()\n",
    "y_cent = [predict_centroid(e)[0] for e in X_test_c]\n",
    "print(\"Centroid baseline accuracy:\", accuracy_score(y_test_c, y_cent))\n",
    "\n",
    "# Open-set threshold suggestion: compute genuine vs impostor cosine scores on validation set\n",
    "# Build per-class centroid from training portion and compute scores: simple approach using split\n",
    "tr, val = next(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(Xn_all, y_all_enc))\n",
    "# compute centroids on tr\n",
    "centroids_tr = {c: Xn_all[tr][y_all_enc[tr]==c].mean(axis=0) for c in np.unique(y_all_enc)}\n",
    "# compute genuine scores and impostor scores on val set\n",
    "genuine_scores = []\n",
    "impostor_scores = []\n",
    "for i, emb in enumerate(Xn_all[val]):\n",
    "    label = y_all_enc[val][i]\n",
    "    emb_norm = emb / np.linalg.norm(emb)\n",
    "    sims = [emb_norm.dot(centroids_tr[c]) for c in centroids_tr]\n",
    "    # genuine score = sim with true class centroid\n",
    "    genuine_scores.append(emb_norm.dot(centroids_tr[label]))\n",
    "    # impostor score = max sim to any other class centroid\n",
    "    impostor_scores.append(max([s for c,s in zip(centroids_tr.keys(), sims) if c != label]))\n",
    "\n",
    "genuine_scores = np.array(genuine_scores); impostor_scores = np.array(impostor_scores)\n",
    "# compute ROC between genuine and impostor by labeling genuine=1, impostor=0 (stack arrays)\n",
    "labels_scores = np.concatenate([np.ones_like(genuine_scores), np.zeros_like(impostor_scores)])\n",
    "scores = np.concatenate([genuine_scores, impostor_scores])\n",
    "fpr, tpr, thresholds = roc_curve(labels_scores, scores)\n",
    "# pick threshold where tpr ~ 0.95 or where (tpr-fpr) is maximized\n",
    "idx = (np.abs(tpr - 0.95)).argmin()\n",
    "suggested_thresh = thresholds[idx]\n",
    "print(f\"Suggested cosine threshold for open-set (approx TPR=0.95): {suggested_thresh:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "          pins_Adriana Lima       1.00      0.97      0.99        35\n",
      "          pins_Alex Lawther       0.91      0.94      0.93        33\n",
      "    pins_Alexandra Daddario       0.97      1.00      0.99        35\n",
      "          pins_Alvaro Morte       0.97      1.00      0.98        32\n",
      "           pins_Amanda Crew       0.68      0.98      0.80        41\n",
      "          pins_Andy Samberg       1.00      0.91      0.95        34\n",
      "         pins_Anne Hathaway       1.00      1.00      1.00        35\n",
      "        pins_Anthony Mackie       0.97      1.00      0.98        32\n",
      "         pins_Avril Lavigne       1.00      0.94      0.97        32\n",
      "           pins_Ben Affleck       0.91      0.97      0.94        32\n",
      "            pins_Bill Gates       0.97      1.00      0.98        31\n",
      "          pins_Bobby Morley       0.97      0.94      0.95        32\n",
      "      pins_Brenton Thwaites       1.00      0.97      0.99        35\n",
      "        pins_Brian J. Smith       0.93      0.88      0.90        32\n",
      "           pins_Brie Larson       0.83      0.97      0.89        35\n",
      "           pins_Chris Evans       1.00      0.97      0.98        33\n",
      "       pins_Chris Hemsworth       1.00      0.94      0.97        33\n",
      "           pins_Chris Pratt       1.00      1.00      1.00        34\n",
      "        pins_Christian Bale       1.00      0.91      0.95        32\n",
      "     pins_Cristiano Ronaldo       1.00      0.97      0.98        30\n",
      "    pins_Danielle Panabaker       0.97      0.97      0.97        34\n",
      "       pins_Dominic Purcell       0.97      0.97      0.97        32\n",
      "        pins_Dwayne Johnson       0.97      0.97      0.97        33\n",
      "          pins_Eliza Taylor       1.00      0.97      0.98        32\n",
      "        pins_Elizabeth Lail       1.00      0.97      0.98        33\n",
      "         pins_Emilia Clarke       1.00      0.97      0.99        35\n",
      "            pins_Emma Stone       1.00      0.94      0.97        32\n",
      "           pins_Emma Watson       0.97      1.00      0.99        35\n",
      "       pins_Gwyneth Paltrow       1.00      1.00      1.00        34\n",
      "           pins_Henry Cavil       1.00      1.00      1.00        34\n",
      "          pins_Hugh Jackman       1.00      0.94      0.97        33\n",
      "            pins_Inbar Lavi       0.72      0.85      0.78        34\n",
      "           pins_Irina Shayk       1.00      0.94      0.97        34\n",
      "         pins_Jake Mcdorman       0.94      1.00      0.97        34\n",
      "           pins_Jason Momoa       1.00      1.00      1.00        34\n",
      "     pins_Jennifer Lawrence       1.00      0.94      0.97        33\n",
      "         pins_Jeremy Renner       1.00      0.94      0.97        34\n",
      "        pins_Jessica Barden       0.86      0.94      0.90        33\n",
      "          pins_Jimmy Fallon       0.62      0.94      0.75        33\n",
      "           pins_Johnny Depp       0.94      1.00      0.97        33\n",
      "           pins_Josh Radnor       0.80      0.97      0.88        34\n",
      "      pins_Katharine Mcphee       1.00      1.00      1.00        34\n",
      "    pins_Katherine Langford       1.00      1.00      1.00        35\n",
      "          pins_Keanu Reeves       0.97      0.94      0.95        32\n",
      "        pins_Krysten Ritter       0.89      0.97      0.93        34\n",
      "     pins_Leonardo DiCaprio       1.00      0.97      0.99        35\n",
      "         pins_Lili Reinhart       0.97      0.97      0.97        34\n",
      "        pins_Lindsey Morgan       0.88      0.91      0.90        33\n",
      "          pins_Lionel Messi       1.00      0.93      0.97        30\n",
      "          pins_Logan Lerman       0.97      0.97      0.97        35\n",
      "      pins_Madelaine Petsch       1.00      0.94      0.97        34\n",
      "       pins_Maisie Williams       1.00      0.94      0.97        34\n",
      "         pins_Maria Pedraza       1.00      0.88      0.93        32\n",
      "    pins_Marie Avgeropoulos       1.00      1.00      1.00        33\n",
      "          pins_Mark Ruffalo       1.00      1.00      1.00        34\n",
      "       pins_Mark Zuckerberg       0.91      0.94      0.92        32\n",
      "             pins_Megan Fox       0.97      1.00      0.99        35\n",
      "           pins_Miley Cyrus       0.97      0.91      0.94        34\n",
      "    pins_Millie Bobby Brown       1.00      0.97      0.99        35\n",
      "       pins_Morena Baccarin       1.00      0.97      0.99        35\n",
      "        pins_Morgan Freeman       1.00      0.97      0.98        31\n",
      "          pins_Nadia Hilker       1.00      0.97      0.98        31\n",
      "        pins_Natalie Dormer       1.00      1.00      1.00        34\n",
      "       pins_Natalie Portman       1.00      0.94      0.97        33\n",
      "   pins_Neil Patrick Harris       1.00      0.90      0.95        31\n",
      "          pins_Pedro Alonso       0.97      0.97      0.97        31\n",
      "          pins_Penn Badgley       1.00      1.00      1.00        33\n",
      "            pins_Rami Malek       0.97      0.94      0.96        35\n",
      "      pins_Rebecca Ferguson       1.00      0.94      0.97        33\n",
      "        pins_Richard Harmon       1.00      0.94      0.97        33\n",
      "               pins_Rihanna       0.97      0.97      0.97        33\n",
      "        pins_Robert De Niro       1.00      0.97      0.98        32\n",
      "      pins_Robert Downey Jr       1.00      0.94      0.97        35\n",
      "   pins_Sarah Wayne Callies       1.00      0.97      0.98        33\n",
      "          pins_Selena Gomez       0.97      0.97      0.97        34\n",
      "pins_Shakira Isabel Mebarak       1.00      0.94      0.97        33\n",
      "         pins_Sophie Turner       1.00      0.94      0.97        35\n",
      "         pins_Stephen Amell       1.00      0.88      0.94        34\n",
      "          pins_Taylor Swift       1.00      0.91      0.95        33\n",
      "            pins_Tom Cruise       1.00      1.00      1.00        34\n",
      "             pins_Tom Hardy       1.00      0.94      0.97        34\n",
      "        pins_Tom Hiddleston       1.00      0.97      0.99        34\n",
      "           pins_Tom Holland       0.97      1.00      0.99        35\n",
      "    pins_Tuppence Middleton       0.70      1.00      0.83        52\n",
      "        pins_Ursula Corbero       1.00      0.99      0.99        67\n",
      "      pins_Wentworth Miller       1.00      0.99      0.99        67\n",
      "             pins_Zac Efron       0.97      0.96      0.96        68\n",
      "               pins_Zendaya       1.00      0.92      0.96        66\n",
      "           pins_Zoe Saldana       1.00      0.98      0.99        81\n",
      "   pins_alycia dabnem carey       1.00      0.97      0.99        35\n",
      "           pins_amber heard       1.00      0.91      0.95        34\n",
      "          pins_barack obama       1.00      1.00      1.00        33\n",
      "        pins_barbara palvin       1.00      1.00      1.00        49\n",
      "         pins_camila mendes       0.94      0.91      0.93        34\n",
      "       pins_elizabeth olsen       1.00      0.97      0.99        35\n",
      "            pins_ellen page       1.00      1.00      1.00        34\n",
      "             pins_elon musk       1.00      0.97      0.98        33\n",
      "             pins_gal gadot       0.95      1.00      0.97        35\n",
      "          pins_grant gustin       1.00      0.91      0.95        34\n",
      "            pins_jeff bezos       0.94      1.00      0.97        30\n",
      "        pins_kiernen shipka       1.00      0.97      0.99        34\n",
      "         pins_margot robbie       1.00      1.00      1.00        35\n",
      "        pins_melissa fumero       0.97      0.91      0.94        33\n",
      "    pins_scarlett johansson       0.97      0.94      0.96        35\n",
      "             pins_tom ellis       1.00      0.94      0.97        34\n",
      "\n",
      "                   accuracy                           0.96      3733\n",
      "                  macro avg       0.97      0.96      0.96      3733\n",
      "               weighted avg       0.97      0.96      0.96      3733\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV: mean=0.9623 std=0.0026\n",
      "Saved centroids to embeddings_cache\\centroids.npy and classes to embeddings_cache\\classes.npy\n",
      "Centroid baseline accuracy: 0.9574069113313689\n",
      "Suggested cosine threshold for open-set (approx TPR=0.95): 0.3818\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "6304f648f09aa0c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:52:24.738291Z",
     "start_time": "2025-11-15T17:52:24.637345Z"
    }
   },
   "source": [
    "# Block 8.2 ‚Äî inference helpers (SVM and centroid)\n",
    "import numpy as np, pickle, cv2, torch\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# load artifacts\n",
    "obj = pickle.load(open(CLF_FILE, 'rb'))\n",
    "clf = obj['clf']; le = obj['le']; norm = obj['norm']\n",
    "centroid_matrix = np.load(CENTROIDS_FILE)\n",
    "classes_order = np.load(CLASSES_FILE)\n",
    "\n",
    "def predict_with_svm(image_path, top_k=3):\n",
    "    img = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n",
    "    face = mtcnn(img)\n",
    "    if face is None:\n",
    "        return None\n",
    "    if face.dim()==3: face = face.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        emb = resnet(face).cpu().numpy().reshape(1,-1)\n",
    "    emb = norm.transform(emb)\n",
    "    probs = clf.predict_proba(emb)[0]\n",
    "    idx = probs.argsort()[::-1][:top_k]\n",
    "    return [(le.classes_[i], float(probs[i])) for i in idx]\n",
    "\n",
    "def predict_with_centroid(image_path, top_k=3):\n",
    "    img = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n",
    "    face = mtcnn(img)\n",
    "    if face is None:\n",
    "        return None\n",
    "    if face.dim()==3: face = face.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        emb = resnet(face).cpu().numpy().reshape(-1)\n",
    "    emb = emb / np.linalg.norm(emb)\n",
    "    sims = centroid_matrix.dot(emb)\n",
    "    idx = sims.argsort()[::-1][:top_k]\n",
    "    return [(classes_order[i], float(sims[i])) for i in idx]\n",
    "\n",
    "print(\"Inference helpers ready. Example:\")\n",
    "# print(predict_with_centroid('path/to/example.jpg'))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference helpers ready. Example:\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "ba9c08b8dbdb3721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:52:41.385929Z",
     "start_time": "2025-11-15T17:52:40.960393Z"
    }
   },
   "source": [
    "# Block 8.3\n",
    "# --- Replace your current loading lines in Block 8.3 with this ---\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "\n",
    "X = np.load('./embeddings_cache/X_emb.npy', mmap_mode='r')    # memmap, safe for large arrays\n",
    "y = np.load('./embeddings_cache/y_lbl.npy', allow_pickle=True)  # y is object array -> allow pickle\n",
    "\n",
    "print(\"Loaded X.shape:\", getattr(X, \"shape\", None), \"dtype:\", X.dtype, \" len(y):\", len(y))\n",
    "\n",
    "# ensure y is string dtype (safe conversion)\n",
    "if y.dtype.kind in (\"S\", \"b\"):   # bytes -> unicode\n",
    "    y = y.astype(str)\n",
    "\n",
    "# ensure X is float32 for normalize (if already float32 no copy; otherwise this WILL copy)\n",
    "if X.dtype != np.float32:\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "# normalize embeddings (may allocate memory if X is not memmapable in your environment)\n",
    "Xn = normalize(X, axis=1)   # if memory is tight, see note below\n",
    "\n",
    "le = LabelEncoder().fit(y)\n",
    "y_enc = le.transform(y)\n",
    "print(\"Normalized Xn.shape:\", Xn.shape, \"unique labels:\", len(le.classes_))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X.shape: (24885, 512) dtype: float32  len(y): 24885\n",
      "Normalized Xn.shape: (24885, 512) unique labels: 105\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "6a10de68445118ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T20:07:44.983933Z",
     "start_time": "2025-11-15T17:52:50.915299Z"
    }
   },
   "source": [
    "# Block 9  - Predict on images and generate detailed CSV report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# ---------- EDIT THIS: Path to folder containing images to predict ----------\n",
    "PREDICT_DIR = \"human_face_dataset/pins_face_recognition\"  # << CHANGE THIS to your test images folder\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Output CSV paths\n",
    "OUTPUT_CSV = \"predictions_results.csv\"\n",
    "OUTPUT_SUMMARY_CSV = \"predictions_summary.csv\"\n",
    "\n",
    "# Load trained model and artifacts\n",
    "print(\"Loading trained model...\")\n",
    "obj = pickle.load(open(CLF_FILE, 'rb'))\n",
    "clf = obj['clf']\n",
    "le = obj['le']\n",
    "norm = obj['norm']\n",
    "print(f\"‚úÖ Model loaded. Can recognize {len(le.classes_)} classes\")\n",
    "\n",
    "# Get all image files\n",
    "PREDICT_PATH = Path(PREDICT_DIR)\n",
    "image_paths = [str(p) for p in sorted(PREDICT_PATH.rglob('*')) if p.suffix.lower() in EXTS]\n",
    "print(f\"Found {len(image_paths)} images in {PREDICT_DIR}\")\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    print(\"‚ö†Ô∏è No images found! Check PREDICT_DIR path.\")\n",
    "else:\n",
    "    # Prepare results storage\n",
    "    results = []\n",
    "    failed_images = []\n",
    "\n",
    "    print(\"\\nProcessing images...\")\n",
    "    for img_path in tqdm(image_paths, desc='Predicting'):\n",
    "        try:\n",
    "            # Load and process image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Resize if too large (speed optimization)\n",
    "            w, h = img.size\n",
    "            max_side = 640\n",
    "            if max(w, h) > max_side:\n",
    "                scale = max_side / max(w, h)\n",
    "                img = img.resize((int(w*scale), int(h*scale)), Image.BILINEAR)\n",
    "\n",
    "            # Detect face\n",
    "            face = mtcnn(img)\n",
    "\n",
    "            if face is None:\n",
    "                failed_images.append((img_path, \"No face detected\"))\n",
    "                continue\n",
    "\n",
    "            # Ensure correct dimensions\n",
    "            if face.dim() == 3:\n",
    "                face = face.unsqueeze(0)\n",
    "\n",
    "            # Get embedding\n",
    "            with torch.no_grad():\n",
    "                emb = resnet(face).cpu().numpy().reshape(1, -1)\n",
    "\n",
    "            # Normalize\n",
    "            emb_norm = norm.transform(emb)\n",
    "\n",
    "            # Predict\n",
    "            pred_class = clf.predict(emb_norm)[0]\n",
    "            pred_label = le.inverse_transform([pred_class])[0]\n",
    "\n",
    "            # Get confidence (probability)\n",
    "            proba = clf.predict_proba(emb_norm)[0]\n",
    "            confidence = float(proba[pred_class])\n",
    "\n",
    "            # Get top 3 predictions\n",
    "            top3_idx = proba.argsort()[::-1][:3]\n",
    "            top3_labels = le.inverse_transform(top3_idx)\n",
    "            top3_probs = proba[top3_idx]\n",
    "\n",
    "            # Get actual label (from parent folder name)\n",
    "            actual_label = Path(img_path).parent.name\n",
    "\n",
    "            # Check if correct\n",
    "            is_correct = (actual_label == pred_label)\n",
    "\n",
    "            # Store result\n",
    "            results.append({\n",
    "                'image_path': img_path,\n",
    "                'filename': Path(img_path).name,\n",
    "                'actual': actual_label,\n",
    "                'predicted': pred_label,\n",
    "                'confidence': confidence,\n",
    "                'correct': is_correct,\n",
    "                'status': 'CORRECT ‚úì' if is_correct else 'WRONG ‚úó',\n",
    "                'top1': top3_labels[0],\n",
    "                'top1_conf': float(top3_probs[0]),\n",
    "                'top2': top3_labels[1] if len(top3_labels) > 1 else '',\n",
    "                'top2_conf': float(top3_probs[1]) if len(top3_probs) > 1 else 0.0,\n",
    "                'top3': top3_labels[2] if len(top3_labels) > 2 else '',\n",
    "                'top3_conf': float(top3_probs[2]) if len(top3_probs) > 2 else 0.0\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_images.append((img_path, str(e)))\n",
    "\n",
    "    # Create DataFrame\n",
    "    if results:\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Sort: Correct predictions first (sorted by confidence desc), then wrong predictions\n",
    "        results_df_sorted = pd.concat([\n",
    "            results_df[results_df['correct']].sort_values('confidence', ascending=False),\n",
    "            results_df[~results_df['correct']].sort_values('confidence', ascending=False)\n",
    "        ])\n",
    "\n",
    "        # Save complete results to CSV\n",
    "        results_df_sorted.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "        # Calculate statistics\n",
    "        total_images = len(results)\n",
    "        correct_count = results_df['correct'].sum()\n",
    "        wrong_count = total_images - correct_count\n",
    "        accuracy = correct_count / total_images if total_images > 0 else 0\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä PREDICTION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"‚úÖ Total images processed: {total_images}\")\n",
    "        print(f\"‚úÖ Correct predictions: {correct_count} ({correct_count/total_images*100:.2f}%)\")\n",
    "        print(f\"‚ùå Wrong predictions: {wrong_count} ({wrong_count/total_images*100:.2f}%)\")\n",
    "        print(f\"üìä Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        print(f\"üìä Average confidence: {results_df['confidence'].mean():.4f}\")\n",
    "        print(f\"‚ùå Failed to process: {len(failed_images)} images\")\n",
    "\n",
    "        # Per-class accuracy summary\n",
    "        class_summary = results_df.groupby('actual').agg({\n",
    "            'correct': ['sum', 'count', 'mean']\n",
    "        }).reset_index()\n",
    "        class_summary.columns = ['class_name', 'correct_count', 'total_count', 'accuracy']\n",
    "        class_summary['wrong_count'] = class_summary['total_count'] - class_summary['correct_count']\n",
    "        class_summary = class_summary.sort_values('accuracy', ascending=False)\n",
    "\n",
    "        # Save class summary\n",
    "        class_summary.to_csv(OUTPUT_SUMMARY_CSV, index=False)\n",
    "\n",
    "        # Show wrong predictions details\n",
    "        wrong_predictions = results_df[~results_df['correct']].copy()\n",
    "\n",
    "        if len(wrong_predictions) > 0:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"‚ùå WRONG PREDICTIONS DETAILS ({len(wrong_predictions)} total)\")\n",
    "            print(\"=\"*80)\n",
    "\n",
    "            # Group wrong predictions by actual class\n",
    "            wrong_by_class = wrong_predictions.groupby('actual').agg({\n",
    "                'filename': 'count',\n",
    "                'predicted': lambda x: ', '.join(x.value_counts().head(3).index.tolist())\n",
    "            }).reset_index()\n",
    "            wrong_by_class.columns = ['actual_class', 'wrong_count', 'predicted_as']\n",
    "            wrong_by_class = wrong_by_class.sort_values('wrong_count', ascending=False)\n",
    "\n",
    "            print(\"\\nClasses with wrong predictions:\")\n",
    "            print(wrong_by_class.to_string(index=False))\n",
    "\n",
    "            print(\"\\n\" + \"-\"*80)\n",
    "            print(\"Individual wrong predictions (showing first 20):\")\n",
    "            print(\"-\"*80)\n",
    "            wrong_display = wrong_predictions[['filename', 'actual', 'predicted', 'confidence']].head(20)\n",
    "            for idx, row in wrong_display.iterrows():\n",
    "                print(f\"  ‚Ä¢ {row['filename']}\")\n",
    "                print(f\"    Actual: {row['actual']} ‚Üí Predicted: {row['predicted']} (confidence: {row['confidence']:.3f})\")\n",
    "\n",
    "            if len(wrong_predictions) > 20:\n",
    "                print(f\"\\n  ... and {len(wrong_predictions)-20} more wrong predictions (see CSV for details)\")\n",
    "        else:\n",
    "            print(\"\\nüéâ NO WRONG PREDICTIONS! Perfect accuracy!\")\n",
    "\n",
    "        # Show classes with perfect accuracy\n",
    "        perfect_classes = class_summary[class_summary['accuracy'] == 1.0]\n",
    "        if len(perfect_classes) > 0:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"üéØ CLASSES WITH 100% ACCURACY ({len(perfect_classes)} classes)\")\n",
    "            print(\"=\"*80)\n",
    "            print(perfect_classes[['class_name', 'total_count']].head(20).to_string(index=False))\n",
    "            if len(perfect_classes) > 20:\n",
    "                print(f\"... and {len(perfect_classes)-20} more classes\")\n",
    "\n",
    "        # Show classes with lowest accuracy\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚ö†Ô∏è CLASSES WITH LOWEST ACCURACY (Bottom 10)\")\n",
    "        print(\"=\"*80)\n",
    "        print(class_summary[['class_name', 'correct_count', 'wrong_count', 'total_count', 'accuracy']].tail(10).to_string(index=False))\n",
    "\n",
    "        # Show correct predictions sample\n",
    "        correct_predictions = results_df[results_df['correct']]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"‚úÖ CORRECT PREDICTIONS SAMPLE (showing 10 of {len(correct_predictions)})\")\n",
    "        print(\"=\"*80)\n",
    "        correct_display = correct_predictions[['filename', 'actual', 'confidence']].head(10)\n",
    "        for idx, row in correct_display.iterrows():\n",
    "            print(f\"  ‚úì {row['filename']}: {row['actual']} (confidence: {row['confidence']:.3f})\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìÅ OUTPUT FILES SAVED:\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"‚úÖ {OUTPUT_CSV}\")\n",
    "        print(f\"   ‚Üí All predictions sorted (correct first, then wrong)\")\n",
    "        print(f\"   ‚Üí Columns: filename, actual, predicted, confidence, status, top3\")\n",
    "        print(f\"\\n‚úÖ {OUTPUT_SUMMARY_CSV}\")\n",
    "        print(f\"   ‚Üí Per-class accuracy summary\")\n",
    "        print(f\"   ‚Üí Columns: class_name, correct_count, wrong_count, total_count, accuracy\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    # Show failed images\n",
    "    if failed_images:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"‚ùå FAILED TO PROCESS ({len(failed_images)} images)\")\n",
    "        print(\"=\"*80)\n",
    "        for path, reason in failed_images[:20]:\n",
    "            print(f\"  ‚Ä¢ {Path(path).name}: {reason}\")\n",
    "        if len(failed_images) > 20:\n",
    "            print(f\"  ... and {len(failed_images)-20} more\")\n",
    "\n",
    "        # Save failed images list\n",
    "        failed_df = pd.DataFrame(failed_images, columns=['image_path', 'error'])\n",
    "        failed_df.to_csv('failed_predictions.csv', index=False)\n",
    "        print(f\"\\n‚úÖ Failed images list saved to: failed_predictions.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n",
      "‚úÖ Model loaded. Can recognize 105 classes\n",
      "Found 24885 images in human_face_dataset/pins_face_recognition\n",
      "\n",
      "Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24885/24885 [2:14:47<00:00,  3.08it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä PREDICTION SUMMARY\n",
      "================================================================================\n",
      "‚úÖ Total images processed: 23391\n",
      "‚úÖ Correct predictions: 22697 (97.03%)\n",
      "‚ùå Wrong predictions: 694 (2.97%)\n",
      "üìä Overall Accuracy: 0.9703 (97.03%)\n",
      "üìä Average confidence: 0.7707\n",
      "‚ùå Failed to process: 1494 images\n",
      "\n",
      "================================================================================\n",
      "‚ùå WRONG PREDICTIONS DETAILS (694 total)\n",
      "================================================================================\n",
      "\n",
      "Classes with wrong predictions:\n",
      "               actual_class  wrong_count                                                           predicted_as\n",
      "        pins_Jessica Barden           14            pins_Inbar Lavi, pins_Alex Lawther, pins_Tuppence Middleton\n",
      "         pins_Maria Pedraza           14               pins_Jimmy Fallon, pins_Amanda Crew, pins_Lindsey Morgan\n",
      "        pins_Lindsey Morgan           14             pins_Tuppence Middleton, pins_Inbar Lavi, pins_Amanda Crew\n",
      "           pins_Brie Larson           13              pins_Jessica Barden, pins_margot robbie, pins_Amanda Crew\n",
      "               pins_Rihanna           13             pins_Inbar Lavi, pins_Tuppence Middleton, pins_Josh Radnor\n",
      "           pins_Miley Cyrus           13 pins_Tuppence Middleton, pins_Amanda Crew, pins_Shakira Isabel Mebarak\n",
      "        pins_melissa fumero           13                  pins_Inbar Lavi, pins_camila mendes, pins_Amanda Crew\n",
      "               pins_Zendaya           13           pins_Tuppence Middleton, pins_Amanda Crew, pins_Selena Gomez\n",
      "    pins_Marie Avgeropoulos           12             pins_Tuppence Middleton, pins_Inbar Lavi, pins_Amanda Crew\n",
      "         pins_Lili Reinhart           11           pins_Tuppence Middleton, pins_Amanda Crew, pins_Jimmy Fallon\n",
      "            pins_Emma Stone           11             pins_Amanda Crew, pins_Tuppence Middleton, pins_Inbar Lavi\n",
      "         pins_camila mendes           11        pins_Tuppence Middleton, pins_Krysten Ritter, pins_Nadia Hilker\n",
      "         pins_Stephen Amell           11           pins_Amanda Crew, pins_Jimmy Fallon, pins_Tuppence Middleton\n",
      "       pins_Maisie Williams           11             pins_Tuppence Middleton, pins_Amanda Crew, pins_Inbar Lavi\n",
      "          pins_Taylor Swift           10                   pins_Amanda Crew, pins_Jimmy Fallon, pins_Inbar Lavi\n",
      "          pins_Bobby Morley           10             pins_Josh Radnor, pins_Jessica Barden, pins_Brian J. Smith\n",
      "            pins_Rami Malek           10                   pins_Jimmy Fallon, pins_Bill Gates, pins_Johnny Depp\n",
      "           pins_Irina Shayk           10                  pins_Amanda Crew, pins_Jessica Barden, pins_Megan Fox\n",
      "        pins_Elizabeth Lail           10            pins_Amanda Crew, pins_Tuppence Middleton, pins_Miley Cyrus\n",
      "        pins_Brian J. Smith           10                   pins_Jimmy Fallon, pins_Amanda Crew, pins_Inbar Lavi\n",
      "         pins_Jeremy Renner            9               pins_Jimmy Fallon, pins_Jessica Barden, pins_Amanda Crew\n",
      "            pins_Inbar Lavi            9         pins_Amanda Crew, pins_Tuppence Middleton, pins_Lindsey Morgan\n",
      "           pins_Ben Affleck            9                   pins_Inbar Lavi, pins_Josh Radnor, pins_Jimmy Fallon\n",
      "    pins_scarlett johansson            9           pins_Amanda Crew, pins_Tuppence Middleton, pins_Taylor Swift\n",
      "            pins_jeff bezos            9                  pins_Amanda Crew, pins_Josh Radnor, pins_Alex Lawther\n",
      "          pins_Pedro Alonso            9                      pins_Jimmy Fallon, pins_Josh Radnor, pins_Rihanna\n",
      "          pins_grant gustin            9             pins_Jimmy Fallon, pins_Alex Lawther, pins_Maisie Williams\n",
      "   pins_Neil Patrick Harris            9                  pins_Jimmy Fallon, pins_Josh Radnor, pins_Amanda Crew\n",
      "          pins_Alex Lawther            9                   pins_Amanda Crew, pins_Brie Larson, pins_Josh Radnor\n",
      "     pins_Cristiano Ronaldo            9                   pins_Josh Radnor, pins_Inbar Lavi, pins_Jimmy Fallon\n",
      "        pins_Dwayne Johnson            8                  pins_Jimmy Fallon, pins_Amanda Crew, pins_Josh Radnor\n",
      "       pins_Chris Hemsworth            8            pins_Josh Radnor, pins_Amanda Crew, pins_Tuppence Middleton\n",
      "           pins_Jason Momoa            8                  pins_Josh Radnor, pins_Jimmy Fallon, pins_Amanda Crew\n",
      "          pins_Nadia Hilker            8          pins_Inbar Lavi, pins_Marie Avgeropoulos, pins_Jessica Barden\n",
      "        pins_Richard Harmon            8                  pins_Jimmy Fallon, pins_Josh Radnor, pins_Amanda Crew\n",
      "        pins_Krysten Ritter            8             pins_Tuppence Middleton, pins_Inbar Lavi, pins_Amanda Crew\n",
      "       pins_Morena Baccarin            8           pins_Inbar Lavi, pins_Tuppence Middleton, pins_camila mendes\n",
      "         pins_Anne Hathaway            8                  pins_Josh Radnor, pins_Inbar Lavi, pins_margot robbie\n",
      "        pins_Anthony Mackie            8              pins_Jimmy Fallon, pins_Josh Radnor, pins_Dominic Purcell\n",
      "           pins_Josh Radnor            7              pins_Inbar Lavi, pins_Dwayne Johnson, pins_Elizabeth Lail\n",
      "           pins_Johnny Depp            7              pins_Leonardo DiCaprio, pins_Josh Radnor, pins_Bill Gates\n",
      "   pins_Sarah Wayne Callies            7           pins_Inbar Lavi, pins_Tuppence Middleton, pins_Lili Reinhart\n",
      "             pins_elon musk            7               pins_Mark Zuckerberg, pins_Inbar Lavi, pins_Jimmy Fallon\n",
      "             pins_Zac Efron            7       pins_Tuppence Middleton, pins_Amanda Crew, pins_Brenton Thwaites\n",
      "    pins_Tuppence Middleton            7              pins_Inbar Lavi, pins_Lindsey Morgan, pins_Jessica Barden\n",
      "          pins_Jimmy Fallon            7                  pins_Amanda Crew, pins_Brie Larson, pins_Bobby Morley\n",
      "    pins_Danielle Panabaker            7             pins_Inbar Lavi, pins_Brie Larson, pins_Tuppence Middleton\n",
      "             pins_tom ellis            7          pins_Tuppence Middleton, pins_Bobby Morley, pins_Jimmy Fallon\n",
      "           pins_Zoe Saldana            7                       pins_Rihanna, pins_Inbar Lavi, pins_Jimmy Fallon\n",
      "       pins_Mark Zuckerberg            7                pins_Tom Holland, pins_Bill Gates, pins_Dominic Purcell\n",
      "           pins_amber heard            6                 pins_Brie Larson, pins_Miley Cyrus, pins_Lili Reinhart\n",
      "           pins_Tom Holland            6      pins_Robert Downey Jr, pins_Jimmy Fallon, pins_Tuppence Middleton\n",
      "pins_Shakira Isabel Mebarak            6                              pins_Tuppence Middleton, pins_Amanda Crew\n",
      "         pins_Sophie Turner            6     pins_Tuppence Middleton, pins_scarlett johansson, pins_Amanda Crew\n",
      "          pins_Lionel Messi            6                     pins_Jake Mcdorman, pins_Josh Radnor, pins_Rihanna\n",
      "       pins_Natalie Portman            6         pins_Millie Bobby Brown, pins_melissa fumero, pins_Brie Larson\n",
      "          pins_Keanu Reeves            6           pins_Josh Radnor, pins_Logan Lerman, pins_Tuppence Middleton\n",
      "         pins_Emilia Clarke            6                 pins_Zendaya, pins_Elizabeth Lail, pins_Jessica Barden\n",
      "         pins_Jake Mcdorman            6               pins_Josh Radnor, pins_Jimmy Fallon, pins_Jessica Barden\n",
      "          pins_Alvaro Morte            6                pins_Josh Radnor, pins_Ben Affleck, pins_Lindsey Morgan\n",
      "        pins_Christian Bale            6                     pins_Zac Efron, pins_Inbar Lavi, pins_Pedro Alonso\n",
      "        pins_Ursula Corbero            5                    pins_Inbar Lavi, pins_Jimmy Fallon, pins_Bill Gates\n",
      "          pins_Selena Gomez            5                   pins_Emma Watson, pins_Brie Larson, pins_Amanda Crew\n",
      "   pins_alycia dabnem carey            5                  pins_Jimmy Fallon, pins_Amanda Crew, pins_Irina Shayk\n",
      "            pins_ellen page            5                pins_camila mendes, pins_Amanda Crew, pins_Jimmy Fallon\n",
      "        pins_Natalie Dormer            5                pins_Inbar Lavi, pins_Madelaine Petsch, pins_Emma Stone\n",
      "           pins_Chris Evans            5                  pins_Josh Radnor, pins_Jimmy Fallon, pins_Ben Affleck\n",
      "          pins_Eliza Taylor            5                pins_Megan Fox, pins_Lili Reinhart, pins_Jessica Barden\n",
      "          pins_Andy Samberg            5                   pins_Amanda Crew, pins_Jimmy Fallon, pins_jeff bezos\n",
      "         pins_Avril Lavigne            5             pins_Amanda Crew, pins_Alexandra Daddario, pins_Inbar Lavi\n",
      "           pins_Amanda Crew            5             pins_Inbar Lavi, pins_Tuppence Middleton, pins_Josh Radnor\n",
      "            pins_Bill Gates            5                pins_Amanda Crew, pins_Mark Zuckerberg, pins_jeff bezos\n",
      "       pins_Dominic Purcell            5           pins_Jimmy Fallon, pins_Josh Radnor, pins_Tuppence Middleton\n",
      "          pins_barack obama            5        pins_Anthony Mackie, pins_Jimmy Fallon, pins_Tuppence Middleton\n",
      "             pins_Megan Fox            5                 pins_Inbar Lavi, pins_camila mendes, pins_Alex Lawther\n",
      "      pins_Katharine Mcphee            5           pins_Amanda Crew, pins_Jimmy Fallon, pins_Tuppence Middleton\n",
      "      pins_Madelaine Petsch            5          pins_Tuppence Middleton, pins_Brie Larson, pins_Lili Reinhart\n",
      "          pins_Logan Lerman            5             pins_Tuppence Middleton, pins_Johnny Depp, pins_Inbar Lavi\n",
      "             pins_Tom Hardy            4            pins_Tuppence Middleton, pins_Tom Holland, pins_Chris Evans\n",
      "          pins_Hugh Jackman            4               pins_Josh Radnor, pins_Anthony Mackie, pins_Alex Lawther\n",
      "     pins_Jennifer Lawrence            4            pins_Brie Larson, pins_Tuppence Middleton, pins_Amanda Crew\n",
      "           pins_Chris Pratt            4                  pins_Inbar Lavi, pins_Ben Affleck, pins_Jake Mcdorman\n",
      "             pins_gal gadot            4                  pins_camila mendes, pins_Inbar Lavi, pins_Amanda Crew\n",
      "      pins_Rebecca Ferguson            4                 pins_Amanda Crew, pins_Inbar Lavi, pins_Krysten Ritter\n",
      "        pins_Tom Hiddleston            4                             pins_Jimmy Fallon, pins_Tuppence Middleton\n",
      "       pins_Gwyneth Paltrow            4                                     pins_Amanda Crew, pins_Brie Larson\n",
      "      pins_Brenton Thwaites            3     pins_Leonardo DiCaprio, pins_Alex Lawther, pins_Tuppence Middleton\n",
      "        pins_barbara palvin            3                 pins_Tuppence Middleton, pins_Rihanna, pins_Inbar Lavi\n",
      "      pins_Robert Downey Jr            3                  pins_Alex Lawther, pins_Rami Malek, pins_Jimmy Fallon\n",
      "    pins_Millie Bobby Brown            3                  pins_Jimmy Fallon, pins_Josh Radnor, pins_Amanda Crew\n",
      "    pins_Katherine Langford            3             pins_Inbar Lavi, pins_Tuppence Middleton, pins_Chris Evans\n",
      "        pins_Robert De Niro            3           pins_Keanu Reeves, pins_Cristiano Ronaldo, pins_Jimmy Fallon\n",
      "           pins_Emma Watson            2                              pins_Tuppence Middleton, pins_Amanda Crew\n",
      "        pins_kiernen shipka            2                                     pins_Brie Larson, pins_Josh Radnor\n",
      "        pins_Morgan Freeman            2                                                        pins_jeff bezos\n",
      "    pins_Alexandra Daddario            2                              pins_Tuppence Middleton, pins_Amanda Crew\n",
      "          pins_Mark Ruffalo            2                                 pins_Josh Radnor, pins_Mark Zuckerberg\n",
      "     pins_Leonardo DiCaprio            2                                  pins_Brian J. Smith, pins_Johnny Depp\n",
      "            pins_Tom Cruise            2                                       pins_Bill Gates, pins_Inbar Lavi\n",
      "           pins_Henry Cavil            1                                                       pins_Amanda Crew\n",
      "          pins_Adriana Lima            1                                                         pins_gal gadot\n",
      "          pins_Penn Badgley            1                                                pins_Tuppence Middleton\n",
      "      pins_Wentworth Miller            1                                                      pins_Jimmy Fallon\n",
      "       pins_elizabeth olsen            1                                                    pins_Jessica Barden\n",
      "         pins_margot robbie            1                                                        pins_Inbar Lavi\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Individual wrong predictions (showing first 20):\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Adriana Lima116_19.jpg\n",
      "    Actual: pins_Adriana Lima ‚Üí Predicted: pins_gal gadot (confidence: 0.080)\n",
      "  ‚Ä¢ Alex Lawther_Aug_259.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Amanda Crew (confidence: 0.172)\n",
      "  ‚Ä¢ Alex Lawther_Aug_275.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Amanda Crew (confidence: 0.214)\n",
      "  ‚Ä¢ Alex Lawther_Aug_277.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Brie Larson (confidence: 0.213)\n",
      "  ‚Ä¢ Alex Lawther_Aug_283.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Amanda Crew (confidence: 0.083)\n",
      "  ‚Ä¢ Alex Lawther_Aug_285.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Josh Radnor (confidence: 0.329)\n",
      "  ‚Ä¢ Alex Lawther_Aug_295.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Amanda Crew (confidence: 0.110)\n",
      "  ‚Ä¢ Alex Lawther_Aug_306.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Jake Mcdorman (confidence: 0.419)\n",
      "  ‚Ä¢ Alex Lawther_Aug_327.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Anthony Mackie (confidence: 0.212)\n",
      "  ‚Ä¢ Alex Lawther_Aug_331.jpg\n",
      "    Actual: pins_Alex Lawther ‚Üí Predicted: pins_Jessica Barden (confidence: 0.054)\n",
      "  ‚Ä¢ Alexandra Daddario_Aug_440.jpg\n",
      "    Actual: pins_Alexandra Daddario ‚Üí Predicted: pins_Tuppence Middleton (confidence: 0.225)\n",
      "  ‚Ä¢ Alexandra Daddario_Aug_443.jpg\n",
      "    Actual: pins_Alexandra Daddario ‚Üí Predicted: pins_Amanda Crew (confidence: 0.086)\n",
      "  ‚Ä¢ Alvaro Morte_Aug_295.jpg\n",
      "    Actual: pins_Alvaro Morte ‚Üí Predicted: pins_Ben Affleck (confidence: 0.098)\n",
      "  ‚Ä¢ Alvaro Morte_Aug_337.jpg\n",
      "    Actual: pins_Alvaro Morte ‚Üí Predicted: pins_Josh Radnor (confidence: 0.150)\n",
      "  ‚Ä¢ Alvaro Morte_Aug_356.jpg\n",
      "    Actual: pins_Alvaro Morte ‚Üí Predicted: pins_Lindsey Morgan (confidence: 0.046)\n",
      "  ‚Ä¢ Alvaro Morte_Aug_361.jpg\n",
      "    Actual: pins_Alvaro Morte ‚Üí Predicted: pins_Jimmy Fallon (confidence: 0.382)\n",
      "  ‚Ä¢ Alvaro Morte_Aug_375.jpg\n",
      "    Actual: pins_Alvaro Morte ‚Üí Predicted: pins_Jessica Barden (confidence: 0.091)\n",
      "  ‚Ä¢ Alvaro Morte_Aug_387.jpg\n",
      "    Actual: pins_Alvaro Morte ‚Üí Predicted: pins_Josh Radnor (confidence: 0.274)\n",
      "  ‚Ä¢ alycia dabnem carey229_134.jpg\n",
      "    Actual: pins_alycia dabnem carey ‚Üí Predicted: pins_Irina Shayk (confidence: 0.070)\n",
      "  ‚Ä¢ alycia dabnem carey_Aug_252.jpg\n",
      "    Actual: pins_alycia dabnem carey ‚Üí Predicted: pins_Jimmy Fallon (confidence: 0.220)\n",
      "\n",
      "  ... and 674 more wrong predictions (see CSV for details)\n",
      "\n",
      "================================================================================\n",
      "‚ö†Ô∏è CLASSES WITH LOWEST ACCURACY (Bottom 10)\n",
      "================================================================================\n",
      "             class_name  correct_count  wrong_count  total_count  accuracy\n",
      "        pins_Emma Stone            205           11          216  0.949074\n",
      "pins_Marie Avgeropoulos            209           12          221  0.945701\n",
      "       pins_Brie Larson            218           13          231  0.943723\n",
      "       pins_Miley Cyrus            217           13          230  0.943478\n",
      "    pins_melissa fumero            210           13          223  0.941704\n",
      "           pins_Rihanna            208           13          221  0.941176\n",
      "           pins_Zendaya            206           13          219  0.940639\n",
      "    pins_Jessica Barden            209           14          223  0.937220\n",
      "    pins_Lindsey Morgan            209           14          223  0.937220\n",
      "     pins_Maria Pedraza            199           14          213  0.934272\n",
      "\n",
      "================================================================================\n",
      "‚úÖ CORRECT PREDICTIONS SAMPLE (showing 10 of 22697)\n",
      "================================================================================\n",
      "  ‚úì Adriana Lima0_0.jpg: pins_Adriana Lima (confidence: 0.787)\n",
      "  ‚úì Adriana Lima101_3.jpg: pins_Adriana Lima (confidence: 0.972)\n",
      "  ‚úì Adriana Lima102_4.jpg: pins_Adriana Lima (confidence: 0.834)\n",
      "  ‚úì Adriana Lima103_5.jpg: pins_Adriana Lima (confidence: 0.831)\n",
      "  ‚úì Adriana Lima104_6.jpg: pins_Adriana Lima (confidence: 0.873)\n",
      "  ‚úì Adriana Lima105_7.jpg: pins_Adriana Lima (confidence: 0.802)\n",
      "  ‚úì Adriana Lima106_8.jpg: pins_Adriana Lima (confidence: 0.760)\n",
      "  ‚úì Adriana Lima107_9.jpg: pins_Adriana Lima (confidence: 0.905)\n",
      "  ‚úì Adriana Lima108_10.jpg: pins_Adriana Lima (confidence: 0.875)\n",
      "  ‚úì Adriana Lima109_11.jpg: pins_Adriana Lima (confidence: 0.408)\n",
      "\n",
      "================================================================================\n",
      "üìÅ OUTPUT FILES SAVED:\n",
      "================================================================================\n",
      "‚úÖ predictions_results.csv\n",
      "   ‚Üí All predictions sorted (correct first, then wrong)\n",
      "   ‚Üí Columns: filename, actual, predicted, confidence, status, top3\n",
      "\n",
      "‚úÖ predictions_summary.csv\n",
      "   ‚Üí Per-class accuracy summary\n",
      "   ‚Üí Columns: class_name, correct_count, wrong_count, total_count, accuracy\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚ùå FAILED TO PROCESS (1494 images)\n",
      "================================================================================\n",
      "  ‚Ä¢ Adriana Lima_Aug_257.jpg: No face detected\n",
      "  ‚Ä¢ Adriana Lima_Aug_258.jpg: No face detected\n",
      "  ‚Ä¢ Adriana Lima_Aug_261.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_257.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_261.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_262.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_268.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_273.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_282.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_294.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_296.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_301.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_308.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_310.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_312.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_316.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_320.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_321.jpg: No face detected\n",
      "  ‚Ä¢ Alex Lawther_Aug_333.jpg: No face detected\n",
      "  ‚Ä¢ Alexandra Daddario_Aug_442.jpg: No face detected\n",
      "  ... and 1474 more\n",
      "\n",
      "‚úÖ Failed images list saved to: failed_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PROCESSING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953ce4c-3691-48a2-9f02-67b3818e2cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
